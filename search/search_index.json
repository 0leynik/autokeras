{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Auto-Keras is an open source software library for automated machine learning (AutoML). It is developed by DATA Lab at Texas A&M University and community contributors. The ultimate goal of AutoML is to provide easily accessible deep learning tools to domain experts with limited data science or machine learning background. Auto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models. Installation To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 . Example Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test) Community You can use Gitter to communicate with people who also interested in Auto-Keras. Citing this work If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, } Support Auto-Keras We accept donations on Open Collective . The money will be used to motivate the developers in the open-source community to contribute code to Auto-Keras. Thank every backer for supporting us! DISCLAIMER Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated. Acknowledgements The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Home"},{"location":"#installation","text":"To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"#example","text":"Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test)","title":"Example"},{"location":"#community","text":"You can use Gitter to communicate with people who also interested in Auto-Keras.","title":"Community"},{"location":"#citing-this-work","text":"If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, }","title":"Citing this work"},{"location":"#support-auto-keras","text":"We accept donations on Open Collective . The money will be used to motivate the developers in the open-source community to contribute code to Auto-Keras. Thank every backer for supporting us!","title":"Support Auto-Keras"},{"location":"#disclaimer","text":"Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated.","title":"DISCLAIMER"},{"location":"#acknowledgements","text":"The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Acknowledgements"},{"location":"about/","text":"About This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"about/#about","text":"This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"docker/","text":"Auto-Keras Docker Download Auto-Keras Docker image The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras Start Auto-Keras Docker container docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference ) Run application : To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py Example : Let's download the mnist example and run it within the container. Download the example : wget https://raw.githubusercontent.com/jhfjhfj1/autokeras/master/examples/mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Getting Started with Docker"},{"location":"docker/#auto-keras-docker","text":"","title":"Auto-Keras Docker"},{"location":"docker/#download-auto-keras-docker-image","text":"The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras","title":"Download Auto-Keras Docker image"},{"location":"docker/#start-auto-keras-docker-container","text":"docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference )","title":"Start Auto-Keras Docker container"},{"location":"docker/#run-application","text":"To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py","title":"Run application :"},{"location":"docker/#example","text":"Let's download the mnist example and run it within the container. Download the example : wget https://raw.githubusercontent.com/jhfjhfj1/autokeras/master/examples/mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Example :"},{"location":"start/","text":"Getting Started Installation The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 . Latest Stable Version ( pip installation): You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras Bleeding Edge Version (manual installation): If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install Example We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs. Data with numpy array (.npy) format. If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays. What if your data are raw image files ( e.g. .jpg, .png, .bmp)? You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier . How to export keras models? from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5') This uses the keras function model.save() to export a single HDF5 file containing the architecture of the model, the weights of the model, the training configuration, and the state of the optimizer. See https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model Note: This is being built into AutoKeras as ImageClassifier().export_keras_model() How to visualize keras models? This is not specific to AutoKeras, however, the following will generate a .PNG visualization of the best model found by AutoKeras: from keras.models import load_model model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it. from keras.utils import plot_model plot_model(model, to_file='my_model.png')","title":"Getting Started"},{"location":"start/#getting-started","text":"","title":"Getting Started"},{"location":"start/#installation","text":"The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"start/#latest-stable-version-pip-installation","text":"You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras","title":"Latest Stable Version (pip installation):"},{"location":"start/#bleeding-edge-version-manual-installation","text":"If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install","title":"Bleeding Edge Version (manual installation):"},{"location":"start/#example","text":"We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs.","title":"Example"},{"location":"start/#data-with-numpy-array-npy-format","text":"If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays.","title":"Data with numpy array (.npy) format."},{"location":"start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp","text":"You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier .","title":"What if your data are raw image files (e.g. .jpg, .png, .bmp)?"},{"location":"start/#how-to-export-keras-models","text":"from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5') This uses the keras function model.save() to export a single HDF5 file containing the architecture of the model, the weights of the model, the training configuration, and the state of the optimizer. See https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model Note: This is being built into AutoKeras as ImageClassifier().export_keras_model()","title":"How to export keras models?"},{"location":"start/#how-to-visualize-keras-models","text":"This is not specific to AutoKeras, however, the following will generate a .PNG visualization of the best model found by AutoKeras: from keras.models import load_model model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it. from keras.utils import plot_model plot_model(model, to_file='my_model.png')","title":"How to visualize keras models?"},{"location":"temp/bayesian/","text":"layer_distance The distance between two layers. layers_distance The distance between the layers of two neural networks. skip_connection_distance The distance between two skip-connections. skip_connections_distance The distance between the skip-connections of two neural networks. edit_distance The distance between two neural networks. Args: x: An instance of NetworkDescriptor. y: An instance of NetworkDescriptor Returns edit_distance_matrix Calculate the edit distance. Args train_x : A list of neural architectures. train_y : A list of neural architectures. Returns vector_distance The Euclidean distance between two vectors. bourgain_embedding_matrix Use Bourgain algorithm to embed the neural architectures based on their edit-distance. Args distance_matrix : A matrix of edit-distances. Returns contain Check if the target descriptor is in the descriptors. IncrementalGaussianProcess Gaussian process regressor. Attributes alpha : A hyperparameter. fit Fit the regressor with more data. Args train_x : A list of NetworkDescriptor. train_y : A list of metric values. incremental_fit Incrementally fit the regressor. first_fit Fit the regressor for the first time. predict Predict the result. Args train_x : A list of NetworkDescriptor. Returns y_mean : The predicted mean. y_std : The predicted standard deviation. BayesianOptimizer A Bayesian optimizer for neural architectures. Attributes searcher : The Searcher which is calling the Bayesian optimizer. t_min : The minimum temperature for simulated annealing. metric : An instance of the Metric subclasses. gpr : A GaussianProcessRegressor for bayesian optimization. beta : The beta in acquisition function. (refer to our paper) search_tree : The network morphism search tree. fit Fit the optimizer with new architectures and performances. Args x_queue : A list of NetworkDescriptor. y_queue : A list of metric values. generate Generate new architecture. Args descriptors : All the searched neural architectures. timeout : An integer. The time limit in seconds. Returns graph : An instance of Graph. A morphed neural network with weights. father_id : The father node ID in the search tree. Elem Elements to be sorted according to metric value. ReverseElem Elements to be reversely sorted according to metric value. SearchTree The network morphism search tree. get_dict A recursive function to return the content of the tree in a dict.","title":"bayesian"},{"location":"temp/bayesian/#layer_distance","text":"The distance between two layers.","title":"layer_distance"},{"location":"temp/bayesian/#layers_distance","text":"The distance between the layers of two neural networks.","title":"layers_distance"},{"location":"temp/bayesian/#skip_connection_distance","text":"The distance between two skip-connections.","title":"skip_connection_distance"},{"location":"temp/bayesian/#skip_connections_distance","text":"The distance between the skip-connections of two neural networks.","title":"skip_connections_distance"},{"location":"temp/bayesian/#edit_distance","text":"The distance between two neural networks. Args: x: An instance of NetworkDescriptor. y: An instance of NetworkDescriptor","title":"edit_distance"},{"location":"temp/bayesian/#returns","text":"","title":"Returns"},{"location":"temp/bayesian/#edit_distance_matrix","text":"Calculate the edit distance.","title":"edit_distance_matrix"},{"location":"temp/bayesian/#args","text":"train_x : A list of neural architectures. train_y : A list of neural architectures.","title":"Args"},{"location":"temp/bayesian/#returns_1","text":"","title":"Returns"},{"location":"temp/bayesian/#vector_distance","text":"The Euclidean distance between two vectors.","title":"vector_distance"},{"location":"temp/bayesian/#bourgain_embedding_matrix","text":"Use Bourgain algorithm to embed the neural architectures based on their edit-distance.","title":"bourgain_embedding_matrix"},{"location":"temp/bayesian/#args_1","text":"distance_matrix : A matrix of edit-distances.","title":"Args"},{"location":"temp/bayesian/#returns_2","text":"","title":"Returns"},{"location":"temp/bayesian/#contain","text":"Check if the target descriptor is in the descriptors.","title":"contain"},{"location":"temp/bayesian/#incrementalgaussianprocess","text":"Gaussian process regressor.","title":"IncrementalGaussianProcess"},{"location":"temp/bayesian/#attributes","text":"alpha : A hyperparameter.","title":"Attributes"},{"location":"temp/bayesian/#fit","text":"Fit the regressor with more data.","title":"fit"},{"location":"temp/bayesian/#args_2","text":"train_x : A list of NetworkDescriptor. train_y : A list of metric values.","title":"Args"},{"location":"temp/bayesian/#incremental_fit","text":"Incrementally fit the regressor.","title":"incremental_fit"},{"location":"temp/bayesian/#first_fit","text":"Fit the regressor for the first time.","title":"first_fit"},{"location":"temp/bayesian/#predict","text":"Predict the result.","title":"predict"},{"location":"temp/bayesian/#args_3","text":"train_x : A list of NetworkDescriptor.","title":"Args"},{"location":"temp/bayesian/#returns_3","text":"y_mean : The predicted mean. y_std : The predicted standard deviation.","title":"Returns"},{"location":"temp/bayesian/#bayesianoptimizer","text":"A Bayesian optimizer for neural architectures.","title":"BayesianOptimizer"},{"location":"temp/bayesian/#attributes_1","text":"searcher : The Searcher which is calling the Bayesian optimizer. t_min : The minimum temperature for simulated annealing. metric : An instance of the Metric subclasses. gpr : A GaussianProcessRegressor for bayesian optimization. beta : The beta in acquisition function. (refer to our paper) search_tree : The network morphism search tree.","title":"Attributes"},{"location":"temp/bayesian/#fit_1","text":"Fit the optimizer with new architectures and performances.","title":"fit"},{"location":"temp/bayesian/#args_4","text":"x_queue : A list of NetworkDescriptor. y_queue : A list of metric values.","title":"Args"},{"location":"temp/bayesian/#generate","text":"Generate new architecture.","title":"generate"},{"location":"temp/bayesian/#args_5","text":"descriptors : All the searched neural architectures. timeout : An integer. The time limit in seconds.","title":"Args"},{"location":"temp/bayesian/#returns_4","text":"graph : An instance of Graph. A morphed neural network with weights. father_id : The father node ID in the search tree.","title":"Returns"},{"location":"temp/bayesian/#elem","text":"Elements to be sorted according to metric value.","title":"Elem"},{"location":"temp/bayesian/#reverseelem","text":"Elements to be reversely sorted according to metric value.","title":"ReverseElem"},{"location":"temp/bayesian/#searchtree","text":"The network morphism search tree.","title":"SearchTree"},{"location":"temp/bayesian/#get_dict","text":"A recursive function to return the content of the tree in a dict.","title":"get_dict"},{"location":"temp/constant/","text":"","title":"Constant"},{"location":"temp/contribute/","text":"Contributing Guide Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. The type of contribution we would be most happy to see is new task modules, e.g. TextClassifier, VideoClassifier. Implement New Task Modules A task module is a comparatively separate module which can handle a specify task. For example, ImageClassifier is the only task module we have for now. The list of task modules we are seeking is all the issues with label \" new task module \". The new task module should be submitted by pull request from the first day you start to develop the module. Make sure your pull request follow the Pull Request Guideline . You can pick any one of them which has not been assigned to anybody yet. If you pick some of the modules which has already been assigned to someone, then we will conduct a thorough evaluation on the benchmark datasets and some preserved datasets. The one performs better in the evaluation will be merged. In general, all new task module should inherit their objects from the Supervised class in autokeras/supervised.py . Reach out to us if you feel there is a special requirement. For every new feature, a new directory should be created inside the /autokeras directory, e.g. text_classifier. All the code contributed should be within the directory. You may put a README.md file in your directory to describe your work. The details of the functions to inherit is in the documentation of autokeras/supervised.py Please also read Code Style Guide , Documentation Guide , Reusable Code Guide , and Testing Guide to ensure your merge request meet our requirements. Other Contributions There are many other ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows. Submit Feedback The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels. Fix Bugs: You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements. Implement Features You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements. Write Documentation The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements. Pull Request Guide Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokeras repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokeras repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now. Code Style Guide This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation. Documentation Guide: The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible. Docstring All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide . Tutorial You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory. Readme File You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use. Testing Guide Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged. Developer Tools Guide We highly recommend you to use Pycharm and virtualenvwrapper . Pycharm Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection. Virtualenvwrapper Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter . Reusable Code Guide You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend. ModelTrainer autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other. Main Contributor List We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Contributing Guide"},{"location":"temp/contribute/#contributing-guide","text":"Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. The type of contribution we would be most happy to see is new task modules, e.g. TextClassifier, VideoClassifier.","title":"Contributing Guide"},{"location":"temp/contribute/#implement-new-task-modules","text":"A task module is a comparatively separate module which can handle a specify task. For example, ImageClassifier is the only task module we have for now. The list of task modules we are seeking is all the issues with label \" new task module \". The new task module should be submitted by pull request from the first day you start to develop the module. Make sure your pull request follow the Pull Request Guideline . You can pick any one of them which has not been assigned to anybody yet. If you pick some of the modules which has already been assigned to someone, then we will conduct a thorough evaluation on the benchmark datasets and some preserved datasets. The one performs better in the evaluation will be merged. In general, all new task module should inherit their objects from the Supervised class in autokeras/supervised.py . Reach out to us if you feel there is a special requirement. For every new feature, a new directory should be created inside the /autokeras directory, e.g. text_classifier. All the code contributed should be within the directory. You may put a README.md file in your directory to describe your work. The details of the functions to inherit is in the documentation of autokeras/supervised.py Please also read Code Style Guide , Documentation Guide , Reusable Code Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement New Task Modules"},{"location":"temp/contribute/#other-contributions","text":"There are many other ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows.","title":"Other Contributions"},{"location":"temp/contribute/#submit-feedback","text":"The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels.","title":"Submit Feedback"},{"location":"temp/contribute/#fix-bugs","text":"You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements.","title":"Fix Bugs:"},{"location":"temp/contribute/#implement-features","text":"You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement Features"},{"location":"temp/contribute/#write-documentation","text":"The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements.","title":"Write Documentation"},{"location":"temp/contribute/#pull-request-guide","text":"Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokeras repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokeras repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now.","title":"Pull Request Guide"},{"location":"temp/contribute/#code-style-guide","text":"This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation.","title":"Code Style Guide"},{"location":"temp/contribute/#documentation-guide","text":"The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible.","title":"Documentation Guide:"},{"location":"temp/contribute/#docstring","text":"All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide .","title":"Docstring"},{"location":"temp/contribute/#tutorial","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory.","title":"Tutorial"},{"location":"temp/contribute/#readme-file","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use.","title":"Readme File"},{"location":"temp/contribute/#testing-guide","text":"Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged.","title":"Testing Guide"},{"location":"temp/contribute/#developer-tools-guide","text":"We highly recommend you to use Pycharm and virtualenvwrapper .","title":"Developer Tools Guide"},{"location":"temp/contribute/#pycharm","text":"Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection.","title":"Pycharm"},{"location":"temp/contribute/#virtualenvwrapper","text":"Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter .","title":"Virtualenvwrapper"},{"location":"temp/contribute/#reusable-code-guide","text":"You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend.","title":"Reusable Code Guide"},{"location":"temp/contribute/#modeltrainer","text":"autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other.","title":"ModelTrainer"},{"location":"temp/contribute/#main-contributor-list","text":"We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Main Contributor List"},{"location":"temp/gan/","text":"DCGAN Deep Convolution Generative Adversary Network init Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation. fit Train only Args x_train : ndarray contained the training data","title":"Gan"},{"location":"temp/gan/#dcgan","text":"Deep Convolution Generative Adversary Network","title":"DCGAN"},{"location":"temp/gan/#init","text":"Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation.","title":"init"},{"location":"temp/gan/#fit","text":"Train only","title":"fit"},{"location":"temp/gan/#args","text":"x_train : ndarray contained the training data","title":"Args"},{"location":"temp/generator/","text":"NetworkGenerator The base class for generating a network. It can be used to generate a CNN or Multi-Layer Perceptron. Attributes n_output_node : Number of output nodes in the network. input_shape : A tuple to represent the input shape. init Initialize the instance. Sets the parameters n_output_node and input_shape for the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. CnnGenerator A class to generate CNN. Attributes n_dim : len(self.input_shape) - 1 conv : A class that represents (n_dim-1) dimensional convolution. dropout : A class that represents (n_dim-1) dimensional dropout. global_avg_pooling : A class that represents (n_dim-1) dimensional Global Average Pooling. pooling : A class that represents (n_dim-1) dimensional pooling. batch_norm : A class that represents (n_dim-1) dimensional batch normalization. init Initialize the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. generate Generates a CNN. Args model_len : An integer. Number of convolutional layers. model_width : An integer. Number of filters for the convolutional layers. Returns MlpGenerator A class to generate Multi-Layer Perceptron. init Initialize the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. If it is 1D, ensure the value is appended by a comma in the tuple. generate Generates a Multi-Layer Perceptron. Args model_len : An integer. Number of hidden layers. model_width : An integer or a list of integers of length model_len . If it is a list, it represents the number of nodes in each hidden layer. If it is an integer, all hidden layers have nodes equal to this value. Returns","title":"generator"},{"location":"temp/generator/#networkgenerator","text":"The base class for generating a network. It can be used to generate a CNN or Multi-Layer Perceptron.","title":"NetworkGenerator"},{"location":"temp/generator/#attributes","text":"n_output_node : Number of output nodes in the network. input_shape : A tuple to represent the input shape.","title":"Attributes"},{"location":"temp/generator/#init","text":"Initialize the instance. Sets the parameters n_output_node and input_shape for the instance.","title":"init"},{"location":"temp/generator/#args","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network.","title":"Args"},{"location":"temp/generator/#cnngenerator","text":"A class to generate CNN.","title":"CnnGenerator"},{"location":"temp/generator/#attributes_1","text":"n_dim : len(self.input_shape) - 1 conv : A class that represents (n_dim-1) dimensional convolution. dropout : A class that represents (n_dim-1) dimensional dropout. global_avg_pooling : A class that represents (n_dim-1) dimensional Global Average Pooling. pooling : A class that represents (n_dim-1) dimensional pooling. batch_norm : A class that represents (n_dim-1) dimensional batch normalization.","title":"Attributes"},{"location":"temp/generator/#init_1","text":"Initialize the instance.","title":"init"},{"location":"temp/generator/#args_1","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network.","title":"Args"},{"location":"temp/generator/#generate","text":"Generates a CNN.","title":"generate"},{"location":"temp/generator/#args_2","text":"model_len : An integer. Number of convolutional layers. model_width : An integer. Number of filters for the convolutional layers.","title":"Args"},{"location":"temp/generator/#returns","text":"","title":"Returns"},{"location":"temp/generator/#mlpgenerator","text":"A class to generate Multi-Layer Perceptron.","title":"MlpGenerator"},{"location":"temp/generator/#init_2","text":"Initialize the instance.","title":"init"},{"location":"temp/generator/#args_3","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. If it is 1D, ensure the value is appended by a comma in the tuple.","title":"Args"},{"location":"temp/generator/#generate_1","text":"Generates a Multi-Layer Perceptron.","title":"generate"},{"location":"temp/generator/#args_4","text":"model_len : An integer. Number of hidden layers. model_width : An integer or a list of integers of length model_len . If it is a list, it represents the number of nodes in each hidden layer. If it is an integer, all hidden layers have nodes equal to this value.","title":"Args"},{"location":"temp/generator/#returns_1","text":"","title":"Returns"},{"location":"temp/graph/","text":"NetworkDescriptor A class describing the neural architecture for neural network kernel. It only record the width of convolutional and dense layers, and the skip-connection types and positions. add_skip_connection Add a skip-connection to the descriptor. Args u : Number of convolutional layers before the starting point. v : Number of convolutional layers before the ending point. connection_type : Must be either CONCAT_CONNECT or ADD_CONNECT. Node A class for intermediate output tensor (node) in the Graph. Attributes shape : A tuple describing the shape of the tensor. Graph A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.) Attributes input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. layer_id_to_output_node_ids : A dict instance mapping from layer identifiers to their output nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism. init Initializer for Graph. Args input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. add_layer Add a layer to the Graph. Args layer : An instance of the subclasses of StubLayer in layers.py. input_node_id : An integer. The ID of the input node of the layer. Returns output_node_id : An integer. The ID of the output node of the layer. n_nodes Return the number of nodes in the model. n_layers Return the number of layers in the model. _add_node Add a new node to node_list and give the node an ID. Args node : An instance of Node. Returns node_id : An integer. _add_edge Add a new layer to the graph. The nodes should be created in advance. _redirect_edge Redirect the layer to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same. _replace_layer Replace the layer with a new layer. topological_order Return the topological order of the node IDs from the input node to the output node. _get_pooling_layers Given two node IDs, return all the pooling layers between them. _depth_first_search Search for all the layers and nodes down the path. A recursive function to search all the layers and nodes between the node in the node_list and the node with target_id. _search Search the graph for all the layers to be widened caused by an operation. It is an recursive function with duplication check to avoid deadlock. It searches from a starting node u until the corresponding layers has been widened. Args u : The starting node ID. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add. to_conv_deeper_model Insert a relu-conv-bn block after the target block. Args target_id : A convolutional layer ID. The new block should be inserted after the block. kernel_size : An integer. The kernel size of the new convolutional layer. to_wider_model Widen the last dimension of the output of the pre_layer. Args pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add. to_dense_deeper_model Insert a dense layer after the target layer. Args target_id : The ID of a dense layer. _insert_new_layers Insert the new_layers after the node with start_node_id. _conv_block_end_node Get the input node ID of the last layer in the block by layer ID. Return the input node ID of the last layer in the convolutional block. Args layer_id : the convolutional layer ID. to_add_skip_model Add a weighted add skip-connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. to_concat_skip_model Add a weighted add concatenate connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. extract_descriptor Extract the the description of the Graph as an instance of NetworkDescriptor. produce_model Build a new torch model based on the current graph. produce_keras_model Build a new keras model based on the current graph. TorchModel A neural network class using pytorch constructed from an instance of Graph.","title":"graph"},{"location":"temp/graph/#networkdescriptor","text":"A class describing the neural architecture for neural network kernel. It only record the width of convolutional and dense layers, and the skip-connection types and positions.","title":"NetworkDescriptor"},{"location":"temp/graph/#add_skip_connection","text":"Add a skip-connection to the descriptor.","title":"add_skip_connection"},{"location":"temp/graph/#args","text":"u : Number of convolutional layers before the starting point. v : Number of convolutional layers before the ending point. connection_type : Must be either CONCAT_CONNECT or ADD_CONNECT.","title":"Args"},{"location":"temp/graph/#node","text":"A class for intermediate output tensor (node) in the Graph.","title":"Node"},{"location":"temp/graph/#attributes","text":"shape : A tuple describing the shape of the tensor.","title":"Attributes"},{"location":"temp/graph/#graph","text":"A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)","title":"Graph"},{"location":"temp/graph/#attributes_1","text":"input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. layer_id_to_output_node_ids : A dict instance mapping from layer identifiers to their output nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism.","title":"Attributes"},{"location":"temp/graph/#init","text":"Initializer for Graph.","title":"init"},{"location":"temp/graph/#args_1","text":"input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time.","title":"Args"},{"location":"temp/graph/#add_layer","text":"Add a layer to the Graph.","title":"add_layer"},{"location":"temp/graph/#args_2","text":"layer : An instance of the subclasses of StubLayer in layers.py. input_node_id : An integer. The ID of the input node of the layer.","title":"Args"},{"location":"temp/graph/#returns","text":"output_node_id : An integer. The ID of the output node of the layer.","title":"Returns"},{"location":"temp/graph/#n_nodes","text":"Return the number of nodes in the model.","title":"n_nodes"},{"location":"temp/graph/#n_layers","text":"Return the number of layers in the model.","title":"n_layers"},{"location":"temp/graph/#_add_node","text":"Add a new node to node_list and give the node an ID.","title":"_add_node"},{"location":"temp/graph/#args_3","text":"node : An instance of Node.","title":"Args"},{"location":"temp/graph/#returns_1","text":"node_id : An integer.","title":"Returns"},{"location":"temp/graph/#_add_edge","text":"Add a new layer to the graph. The nodes should be created in advance.","title":"_add_edge"},{"location":"temp/graph/#_redirect_edge","text":"Redirect the layer to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.","title":"_redirect_edge"},{"location":"temp/graph/#_replace_layer","text":"Replace the layer with a new layer.","title":"_replace_layer"},{"location":"temp/graph/#topological_order","text":"Return the topological order of the node IDs from the input node to the output node.","title":"topological_order"},{"location":"temp/graph/#_get_pooling_layers","text":"Given two node IDs, return all the pooling layers between them.","title":"_get_pooling_layers"},{"location":"temp/graph/#_depth_first_search","text":"Search for all the layers and nodes down the path. A recursive function to search all the layers and nodes between the node in the node_list and the node with target_id.","title":"_depth_first_search"},{"location":"temp/graph/#_search","text":"Search the graph for all the layers to be widened caused by an operation. It is an recursive function with duplication check to avoid deadlock. It searches from a starting node u until the corresponding layers has been widened.","title":"_search"},{"location":"temp/graph/#args_4","text":"u : The starting node ID. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#to_conv_deeper_model","text":"Insert a relu-conv-bn block after the target block.","title":"to_conv_deeper_model"},{"location":"temp/graph/#args_5","text":"target_id : A convolutional layer ID. The new block should be inserted after the block. kernel_size : An integer. The kernel size of the new convolutional layer.","title":"Args"},{"location":"temp/graph/#to_wider_model","text":"Widen the last dimension of the output of the pre_layer.","title":"to_wider_model"},{"location":"temp/graph/#args_6","text":"pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#to_dense_deeper_model","text":"Insert a dense layer after the target layer.","title":"to_dense_deeper_model"},{"location":"temp/graph/#args_7","text":"target_id : The ID of a dense layer.","title":"Args"},{"location":"temp/graph/#_insert_new_layers","text":"Insert the new_layers after the node with start_node_id.","title":"_insert_new_layers"},{"location":"temp/graph/#_conv_block_end_node","text":"Get the input node ID of the last layer in the block by layer ID. Return the input node ID of the last layer in the convolutional block.","title":"_conv_block_end_node"},{"location":"temp/graph/#args_8","text":"layer_id : the convolutional layer ID.","title":"Args"},{"location":"temp/graph/#to_add_skip_model","text":"Add a weighted add skip-connection from after start node to end node.","title":"to_add_skip_model"},{"location":"temp/graph/#args_9","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#to_concat_skip_model","text":"Add a weighted add concatenate connection from after start node to end node.","title":"to_concat_skip_model"},{"location":"temp/graph/#args_10","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#extract_descriptor","text":"Extract the the description of the Graph as an instance of NetworkDescriptor.","title":"extract_descriptor"},{"location":"temp/graph/#produce_model","text":"Build a new torch model based on the current graph.","title":"produce_model"},{"location":"temp/graph/#produce_keras_model","text":"Build a new keras model based on the current graph.","title":"produce_keras_model"},{"location":"temp/graph/#torchmodel","text":"A neural network class using pytorch constructed from an instance of Graph.","title":"TorchModel"},{"location":"temp/image_supervised/","text":"read_images Read the images from the path and return their numpy.ndarray instance. Return a numpy.ndarray instance containing the training data. Args img_file_names : List containing images names. images_dir_path : Path to the directory containing images. load_image_dataset Load images from the files and labels from a csv file. Second, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path . Args csv_file_path : CSV file path. images_path : Path where images exist. Returns x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : The labels. ImageSupervised The image classifier class. It is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset. Attributes path : A path to the directory to save the classifier. y_encoder : An instance of OneHotEncoder for y_train (array of categorical labels). verbose : A boolean value indicating the verbosity mode. searcher_args : A dictionary containing the parameters for the searcher's init function. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. init Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. export_keras_model Exports the best Keras model to the given filename. export_autokeras_model Creates and Exports the AutoKeras model to the given filename. PortableImageSupervised init Initialize the instance. Args: graph: The graph form of the learned model predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test .","title":"image_supervised"},{"location":"temp/image_supervised/#read_images","text":"Read the images from the path and return their numpy.ndarray instance. Return a numpy.ndarray instance containing the training data.","title":"read_images"},{"location":"temp/image_supervised/#args","text":"img_file_names : List containing images names. images_dir_path : Path to the directory containing images.","title":"Args"},{"location":"temp/image_supervised/#load_image_dataset","text":"Load images from the files and labels from a csv file. Second, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path .","title":"load_image_dataset"},{"location":"temp/image_supervised/#args_1","text":"csv_file_path : CSV file path. images_path : Path where images exist.","title":"Args"},{"location":"temp/image_supervised/#returns","text":"x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : The labels.","title":"Returns"},{"location":"temp/image_supervised/#imagesupervised","text":"The image classifier class. It is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset.","title":"ImageSupervised"},{"location":"temp/image_supervised/#attributes","text":"path : A path to the directory to save the classifier. y_encoder : An instance of OneHotEncoder for y_train (array of categorical labels). verbose : A boolean value indicating the verbosity mode. searcher_args : A dictionary containing the parameters for the searcher's init function. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default.","title":"Attributes"},{"location":"temp/image_supervised/#init","text":"Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.","title":"init"},{"location":"temp/image_supervised/#args_2","text":"verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default.","title":"Args"},{"location":"temp/image_supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/image_supervised/#args_3","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/image_supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/image_supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/image_supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/image_supervised/#args_4","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/image_supervised/#export_keras_model","text":"Exports the best Keras model to the given filename.","title":"export_keras_model"},{"location":"temp/image_supervised/#export_autokeras_model","text":"Creates and Exports the AutoKeras model to the given filename.","title":"export_autokeras_model"},{"location":"temp/image_supervised/#portableimagesupervised","text":"","title":"PortableImageSupervised"},{"location":"temp/image_supervised/#init_1","text":"Initialize the instance. Args: graph: The graph form of the learned model","title":"init"},{"location":"temp/image_supervised/#predict_1","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/image_supervised/#args_5","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/image_supervised/#returns_2","text":"","title":"Returns"},{"location":"temp/image_supervised/#evaluate_1","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/layer_transformer/","text":"","title":"Layer transformer"},{"location":"temp/layers/","text":"","title":"Layers"},{"location":"temp/loss_function/","text":"","title":"Loss function"},{"location":"temp/metric/","text":"","title":"Metric"},{"location":"temp/model_trainer/","text":"ModelTrainer A class that is used to train the model. This class can train a Pytorch model with the given data loaders. The metric, loss_function, and model must be compatible with each other. Please see the details in the Attributes. Attributes device : A string. Indicating the device to use. 'cuda' or 'cpu'. model : An instance of Pytorch Module. The model that will be trained. train_loader : Training data wrapped in batches in Pytorch Dataloader. test_loader : Testing data wrapped in batches in Pytorch Dataloader. loss_function : A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. optimizer : The optimizer is chosen to use the Pytorch Adam optimizer. early_stop : An instance of class EarlyStop. metric : It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose : Verbosity mode. init Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose train_model Train the model. Args max_iter_num : An integer. The maximum number of epochs to train the model. The training will stop when this number is reached. max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease. The training will stop when this number is reached. GANModelTrainer init Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose","title":"model_trainer"},{"location":"temp/model_trainer/#modeltrainer","text":"A class that is used to train the model. This class can train a Pytorch model with the given data loaders. The metric, loss_function, and model must be compatible with each other. Please see the details in the Attributes.","title":"ModelTrainer"},{"location":"temp/model_trainer/#attributes","text":"device : A string. Indicating the device to use. 'cuda' or 'cpu'. model : An instance of Pytorch Module. The model that will be trained. train_loader : Training data wrapped in batches in Pytorch Dataloader. test_loader : Testing data wrapped in batches in Pytorch Dataloader. loss_function : A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. optimizer : The optimizer is chosen to use the Pytorch Adam optimizer. early_stop : An instance of class EarlyStop. metric : It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose : Verbosity mode.","title":"Attributes"},{"location":"temp/model_trainer/#init","text":"Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose","title":"init"},{"location":"temp/model_trainer/#train_model","text":"Train the model.","title":"train_model"},{"location":"temp/model_trainer/#args","text":"max_iter_num : An integer. The maximum number of epochs to train the model. The training will stop when this number is reached. max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease. The training will stop when this number is reached.","title":"Args"},{"location":"temp/model_trainer/#ganmodeltrainer","text":"","title":"GANModelTrainer"},{"location":"temp/model_trainer/#init_1","text":"Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose","title":"init"},{"location":"temp/net_module/","text":"NetworkModule fit Search the best CnnModule. Args n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1) train_data : A PyTorch DataLoader instance represents the training data test_data : A PyTorch DataLoader instance represents the testing data time_limit : A integer value represents the time limit on searching for models. final_fit Final training after found the best architecture. Args trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. train_data : A DataLoader instance representing the training data test_data : A DataLoader instance representing the testing data","title":"Net module"},{"location":"temp/net_module/#networkmodule","text":"","title":"NetworkModule"},{"location":"temp/net_module/#fit","text":"Search the best CnnModule.","title":"fit"},{"location":"temp/net_module/#args","text":"n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1) train_data : A PyTorch DataLoader instance represents the training data test_data : A PyTorch DataLoader instance represents the testing data time_limit : A integer value represents the time limit on searching for models.","title":"Args"},{"location":"temp/net_module/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/net_module/#args_1","text":"trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. train_data : A DataLoader instance representing the training data test_data : A DataLoader instance representing the testing data","title":"Args"},{"location":"temp/net_transformer/","text":"","title":"Net transformer"},{"location":"temp/preprocessor/","text":"OneHotEncoder A class that can format data. This class provides ways to transform data's classification label into vector. Attributes data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label. init Initialize a OneHotEncoder fit Create mapping from label to vector, and vector to label. transform Get vector for every element in the data array. inverse_transform Get label for every element in data. Cutout Randomly mask out one or more patches from an image. Args: n_holes (int): Number of patches to cut out of each image. length (int): The length (in pixels) of each square patch. call Args: img (Tensor): Tensor image of size (C, H, W). Returns: Tensor: Image with n_holes of dimension length x length cut out of it.","title":"preprocessor"},{"location":"temp/preprocessor/#onehotencoder","text":"A class that can format data. This class provides ways to transform data's classification label into vector.","title":"OneHotEncoder"},{"location":"temp/preprocessor/#attributes","text":"data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label.","title":"Attributes"},{"location":"temp/preprocessor/#init","text":"Initialize a OneHotEncoder","title":"init"},{"location":"temp/preprocessor/#fit","text":"Create mapping from label to vector, and vector to label.","title":"fit"},{"location":"temp/preprocessor/#transform","text":"Get vector for every element in the data array.","title":"transform"},{"location":"temp/preprocessor/#inverse_transform","text":"Get label for every element in data.","title":"inverse_transform"},{"location":"temp/preprocessor/#cutout","text":"Randomly mask out one or more patches from an image. Args: n_holes (int): Number of patches to cut out of each image. length (int): The length (in pixels) of each square patch.","title":"Cutout"},{"location":"temp/preprocessor/#call","text":"Args: img (Tensor): Tensor image of size (C, H, W). Returns: Tensor: Image with n_holes of dimension length x length cut out of it.","title":"call"},{"location":"temp/search/","text":"train Train the neural architecture. Searcher Class to search for neural architectures. This class generate new architectures, call the trainer to train it, and update the Bayesian optimizer. Attributes n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. beta : A float. The beta in the UCB acquisition function. t_min : A float. The minimum temperature during simulated annealing. bo : An instance of BayesianOptimizer. init Initialize the Searcher. Args n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. beta : A float. The beta in the UCB acquisition function. t_min : A float. The minimum temperature during simulated annealing. add_model Append the information of evaluated architecture to history. init_search Call the generators to generate the initial architectures for the search. search Run the search loop of training, generating and updating once. The function will run the training and generate in parallel. Then it will update the controller. The training is just pop out a graph from the training_queue and train it. The generate will call teh self.generate function. The update will call the self.update function. Args train_data : An instance of DataLoader. test_data : An instance of Dataloader. timeout : An integer, time limit in seconds. update Update the controller with evaluation result of a neural architecture. Args other_info : Anything. In our case it is the father ID in the search tree. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value. model_id : An integer. generate Generate the next neural architecture. Args remaining_time : The remaining time in seconds. Returns other_info : Anything to be saved in the training queue together with the architecture. generated_graph : An instance of Graph. export_json Export a json file of the search process.","title":"search"},{"location":"temp/search/#train","text":"Train the neural architecture.","title":"train"},{"location":"temp/search/#searcher","text":"Class to search for neural architectures. This class generate new architectures, call the trainer to train it, and update the Bayesian optimizer.","title":"Searcher"},{"location":"temp/search/#attributes","text":"n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. beta : A float. The beta in the UCB acquisition function. t_min : A float. The minimum temperature during simulated annealing. bo : An instance of BayesianOptimizer.","title":"Attributes"},{"location":"temp/search/#init","text":"Initialize the Searcher.","title":"init"},{"location":"temp/search/#args","text":"n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. beta : A float. The beta in the UCB acquisition function. t_min : A float. The minimum temperature during simulated annealing.","title":"Args"},{"location":"temp/search/#add_model","text":"Append the information of evaluated architecture to history.","title":"add_model"},{"location":"temp/search/#init_search","text":"Call the generators to generate the initial architectures for the search.","title":"init_search"},{"location":"temp/search/#search","text":"Run the search loop of training, generating and updating once. The function will run the training and generate in parallel. Then it will update the controller. The training is just pop out a graph from the training_queue and train it. The generate will call teh self.generate function. The update will call the self.update function.","title":"search"},{"location":"temp/search/#args_1","text":"train_data : An instance of DataLoader. test_data : An instance of Dataloader. timeout : An integer, time limit in seconds.","title":"Args"},{"location":"temp/search/#update","text":"Update the controller with evaluation result of a neural architecture.","title":"update"},{"location":"temp/search/#args_2","text":"other_info : Anything. In our case it is the father ID in the search tree. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value. model_id : An integer.","title":"Args"},{"location":"temp/search/#generate","text":"Generate the next neural architecture.","title":"generate"},{"location":"temp/search/#args_3","text":"remaining_time : The remaining time in seconds.","title":"Args"},{"location":"temp/search/#returns","text":"other_info : Anything to be saved in the training queue together with the architecture. generated_graph : An instance of Graph.","title":"Returns"},{"location":"temp/search/#export_json","text":"Export a json file of the search process.","title":"export_json"},{"location":"temp/supervised/","text":"Supervised The base class for all supervised task. Attributes verbose : A boolean value indicating the verbosity mode. init Initialize the instance. Args verbose : A boolean of whether the search process will be printed to stdout. fit Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train . Args x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. x_test : A numpy.ndarray instance containing the testing data y_test : A numpy.ndarray instance containing the label of the testing data. time_limit : The time limit for the search in seconds. final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . PortableClass init Initialize the instance. Args graph : The graph form of the learned model predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test .","title":"supervised"},{"location":"temp/supervised/#supervised","text":"The base class for all supervised task.","title":"Supervised"},{"location":"temp/supervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/supervised/#init","text":"Initialize the instance.","title":"init"},{"location":"temp/supervised/#args","text":"verbose : A boolean of whether the search process will be printed to stdout.","title":"Args"},{"location":"temp/supervised/#fit","text":"Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/supervised/#args_1","text":"x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. x_test : A numpy.ndarray instance containing the testing data y_test : A numpy.ndarray instance containing the label of the testing data. time_limit : The time limit for the search in seconds.","title":"Args"},{"location":"temp/supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/supervised/#args_2","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_3","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/supervised/#portableclass","text":"","title":"PortableClass"},{"location":"temp/supervised/#init_1","text":"Initialize the instance.","title":"init"},{"location":"temp/supervised/#args_4","text":"graph : The graph form of the learned model","title":"Args"},{"location":"temp/supervised/#predict_1","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_5","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate_1","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/text_preprocessor/","text":"clean_str Tokenization/string cleaning for all string. Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py tokenlize_text Tokenlize text class. Vectorize a text corpus by transform each text in texts to a sequence of integers. Attributes max_num_words : int, max number of words in the dictionary max_seq_length : int, the length of each text sequence, padding if shorter, trim is longer x_train : list contains text data y_train : list contains label data","title":"Text preprocessor"},{"location":"temp/text_preprocessor/#clean_str","text":"Tokenization/string cleaning for all string. Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py","title":"clean_str"},{"location":"temp/text_preprocessor/#tokenlize_text","text":"Tokenlize text class. Vectorize a text corpus by transform each text in texts to a sequence of integers.","title":"tokenlize_text"},{"location":"temp/text_preprocessor/#attributes","text":"max_num_words : int, max number of words in the dictionary max_seq_length : int, the length of each text sequence, padding if shorter, trim is longer x_train : list contains text data y_train : list contains label data","title":"Attributes"},{"location":"temp/text_supervised/","text":"TextClassifier fit Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train . Args x : A numpy.ndarray instance containing the training data. y : A numpy.ndarray instance containing the label of the training data. time_limit : The time limit for the search in seconds. y_test : x_test : final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns","title":"Text supervised"},{"location":"temp/text_supervised/#textclassifier","text":"","title":"TextClassifier"},{"location":"temp/text_supervised/#fit","text":"Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/text_supervised/#args","text":"x : A numpy.ndarray instance containing the training data. y : A numpy.ndarray instance containing the label of the training data. time_limit : The time limit for the search in seconds. y_test : x_test :","title":"Args"},{"location":"temp/text_supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/text_supervised/#args_1","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/text_supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/text_supervised/#args_2","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/text_supervised/#returns","text":"","title":"Returns"},{"location":"temp/unsupervised/","text":"Unsupervised The base class for all unsupervised task Attributes verbose : A boolean value indicating the verbosity mode. init Args: verbose: A boolean of whether the search process will be printed to stdout. fit Args: x_train: A numpy.ndarray instance containing the training data. generate Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"Unsupervised"},{"location":"temp/unsupervised/#unsupervised","text":"The base class for all unsupervised task","title":"Unsupervised"},{"location":"temp/unsupervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/unsupervised/#init","text":"Args: verbose: A boolean of whether the search process will be printed to stdout.","title":"init"},{"location":"temp/unsupervised/#fit","text":"Args: x_train: A numpy.ndarray instance containing the training data.","title":"fit"},{"location":"temp/unsupervised/#generate","text":"Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"generate"},{"location":"temp/utils/","text":"ensure_dir Create directory if it does not exist. ensure_file_dir Create path if it does not exist. has_file Check if the given path exists. pickle_from_file Load the pickle file from the provided path and returns the object. pickle_to_file Save the pickle file to the specified path. get_device If CUDA is available, use CUDA device, else use CPU device. When choosing from CUDA devices, this function will choose the one with max memory available. temp_folder_generator Create and return a temporary directory with the path name '/temp_dir_name/autokeras' (E:g:- /tmp/autokeras). download_file Download the file specified in file_link and saves it in file_path . download_file_with_extract Download the file specified in file_link , save to file_path and extract to the directory extract_path . verbose_print Print information about the operation performed on father model to obtain current model and father's id. validate_xy Validate x_train 's type and the shape of x_train , y_train . read_csv_file Read the csv file and returns two separate list containing file names and their labels. Args csv_file_path : Path to the CSV file. Returns file_names : List containing files names. file_label : List containing their respective labels. read_image Read the image contained in the provided path image_path . compute_image_resize_params Compute median height and width of all images in data. These values are used to resize the images at later point. Number of channels do not change from the original images. Currently, only 2-D images are supported. Args data : 2-D Image data with shape N x H x W x C. Returns median height : Median height of all images in the data. median width : Median width of all images in the data. resize_image_data Resize images to provided height and width. Resize all images in data to size h x w x c, where h is the height, w is the width and c is the number of channels. The number of channels c does not change from data. The function supports only 2-D image data. Args data : 2-D Image data with shape N x H x W x C. h : Image resize height. w : Image resize width. Returns data : Resize data. get_system Get the current system environment. If the current system is not supported, raise an exception. Returns","title":"utils"},{"location":"temp/utils/#ensure_dir","text":"Create directory if it does not exist.","title":"ensure_dir"},{"location":"temp/utils/#ensure_file_dir","text":"Create path if it does not exist.","title":"ensure_file_dir"},{"location":"temp/utils/#has_file","text":"Check if the given path exists.","title":"has_file"},{"location":"temp/utils/#pickle_from_file","text":"Load the pickle file from the provided path and returns the object.","title":"pickle_from_file"},{"location":"temp/utils/#pickle_to_file","text":"Save the pickle file to the specified path.","title":"pickle_to_file"},{"location":"temp/utils/#get_device","text":"If CUDA is available, use CUDA device, else use CPU device. When choosing from CUDA devices, this function will choose the one with max memory available.","title":"get_device"},{"location":"temp/utils/#temp_folder_generator","text":"Create and return a temporary directory with the path name '/temp_dir_name/autokeras' (E:g:- /tmp/autokeras).","title":"temp_folder_generator"},{"location":"temp/utils/#download_file","text":"Download the file specified in file_link and saves it in file_path .","title":"download_file"},{"location":"temp/utils/#download_file_with_extract","text":"Download the file specified in file_link , save to file_path and extract to the directory extract_path .","title":"download_file_with_extract"},{"location":"temp/utils/#verbose_print","text":"Print information about the operation performed on father model to obtain current model and father's id.","title":"verbose_print"},{"location":"temp/utils/#validate_xy","text":"Validate x_train 's type and the shape of x_train , y_train .","title":"validate_xy"},{"location":"temp/utils/#read_csv_file","text":"Read the csv file and returns two separate list containing file names and their labels.","title":"read_csv_file"},{"location":"temp/utils/#args","text":"csv_file_path : Path to the CSV file.","title":"Args"},{"location":"temp/utils/#returns","text":"file_names : List containing files names. file_label : List containing their respective labels.","title":"Returns"},{"location":"temp/utils/#read_image","text":"Read the image contained in the provided path image_path .","title":"read_image"},{"location":"temp/utils/#compute_image_resize_params","text":"Compute median height and width of all images in data. These values are used to resize the images at later point. Number of channels do not change from the original images. Currently, only 2-D images are supported.","title":"compute_image_resize_params"},{"location":"temp/utils/#args_1","text":"data : 2-D Image data with shape N x H x W x C.","title":"Args"},{"location":"temp/utils/#returns_1","text":"median height : Median height of all images in the data. median width : Median width of all images in the data.","title":"Returns"},{"location":"temp/utils/#resize_image_data","text":"Resize images to provided height and width. Resize all images in data to size h x w x c, where h is the height, w is the width and c is the number of channels. The number of channels c does not change from data. The function supports only 2-D image data.","title":"resize_image_data"},{"location":"temp/utils/#args_2","text":"data : 2-D Image data with shape N x H x W x C. h : Image resize height. w : Image resize width.","title":"Args"},{"location":"temp/utils/#returns_2","text":"data : Resize data.","title":"Returns"},{"location":"temp/utils/#get_system","text":"Get the current system environment. If the current system is not supported, raise an exception.","title":"get_system"},{"location":"temp/utils/#returns_3","text":"","title":"Returns"}]}