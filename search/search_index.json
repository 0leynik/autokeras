{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Auto-Keras is an open source software library for automated machine learning (AutoML). It is developed by DATA Lab at Texas A&M University and community contributors. The ultimate goal of AutoML is to provide easily accessible deep learning tools to domain experts with limited data science or machine learning background. Auto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models. Installation To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 . Example Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test) Community You can use Gitter to communicate with people who also interested in Auto-Keras. You can follow us on Twitter. We will constantly post our new features and releases. Moreover, we will post new feature request for the developers from the open-source community to contribute code and documentation. Follow @autokeras Citing this work If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, } Support Auto-Keras We accept donations on Open Collective . The money will be used to motivate the developers in the open-source community to contribute code to Auto-Keras. Thank every backer for supporting us! DISCLAIMER Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated. Acknowledgements The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Home"},{"location":"#installation","text":"To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"#example","text":"Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test)","title":"Example"},{"location":"#community","text":"You can use Gitter to communicate with people who also interested in Auto-Keras. You can follow us on Twitter. We will constantly post our new features and releases. Moreover, we will post new feature request for the developers from the open-source community to contribute code and documentation. Follow @autokeras","title":"Community"},{"location":"#citing-this-work","text":"If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, }","title":"Citing this work"},{"location":"#support-auto-keras","text":"We accept donations on Open Collective . The money will be used to motivate the developers in the open-source community to contribute code to Auto-Keras. Thank every backer for supporting us!","title":"Support Auto-Keras"},{"location":"#disclaimer","text":"Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated.","title":"DISCLAIMER"},{"location":"#acknowledgements","text":"The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Acknowledgements"},{"location":"about/","text":"About This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"about/#about","text":"This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"docker/","text":"Auto-Keras Docker Download Auto-Keras Docker image The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras Start Auto-Keras Docker container docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference ) Run application : To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py Example : Let's download the mnist example and run it within the container. Download the example : wget https://raw.githubusercontent.com/jhfjhfj1/autokeras/master/examples/mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Getting Started with Docker"},{"location":"docker/#auto-keras-docker","text":"","title":"Auto-Keras Docker"},{"location":"docker/#download-auto-keras-docker-image","text":"The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras","title":"Download Auto-Keras Docker image"},{"location":"docker/#start-auto-keras-docker-container","text":"docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference )","title":"Start Auto-Keras Docker container"},{"location":"docker/#run-application","text":"To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py","title":"Run application :"},{"location":"docker/#example","text":"Let's download the mnist example and run it within the container. Download the example : wget https://raw.githubusercontent.com/jhfjhfj1/autokeras/master/examples/mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Example :"},{"location":"start/","text":"Getting Started Installation The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 . Latest Stable Version ( pip installation): You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras Bleeding Edge Version (manual installation): If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install Example We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs. Data with numpy array (.npy) format. If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays. What if your data are raw image files ( e.g. .jpg, .png, .bmp)? You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier . How to export keras models? from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5') This uses the keras function model.save() to export a single HDF5 file containing the architecture of the model, the weights of the model, the training configuration, and the state of the optimizer. See https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model Note: This is being built into AutoKeras as ImageClassifier().export_keras_model() How to visualize keras models? This is not specific to AutoKeras, however, the following will generate a .PNG visualization of the best model found by AutoKeras: from keras.models import load_model model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it. from keras.utils import plot_model plot_model(model, to_file='my_model.png') How to visualize the best selected architecture ? While trying to create a model, let's say an Image classifier on MNIST, there is a facility for the user to visualize a .PDF depiction of the best architecture that was chosen by autokeras, after model training is complete. Prerequisites : 1) graphviz must be installed in your system. Refer Installation Guide 2) Additionally, also install \"graphviz\" python package using pip / conda pip : pip install graphviz conda : conda install -c conda-forge python-graphviz If the above installations are complete, proceed with the following steps : Step 1 : Specify a path before starting your model training clf = ImageClassifier(path=\"~/automodels/\",verbose=True, augment=False) # Give a custom path of your choice clf.fit(x_train, y_train, time_limit=30 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) Step 2 : After the model training is complete, run examples/visualize.py , whilst passing the same path as parameter if __name__ == '__main__': visualize('~/automodels/')","title":"Getting Started"},{"location":"start/#getting-started","text":"","title":"Getting Started"},{"location":"start/#installation","text":"The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"start/#latest-stable-version-pip-installation","text":"You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras","title":"Latest Stable Version (pip installation):"},{"location":"start/#bleeding-edge-version-manual-installation","text":"If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install","title":"Bleeding Edge Version (manual installation):"},{"location":"start/#example","text":"We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs.","title":"Example"},{"location":"start/#data-with-numpy-array-npy-format","text":"If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays.","title":"Data with numpy array (.npy) format."},{"location":"start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp","text":"You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier .","title":"What if your data are raw image files (e.g. .jpg, .png, .bmp)?"},{"location":"start/#how-to-export-keras-models","text":"from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5') This uses the keras function model.save() to export a single HDF5 file containing the architecture of the model, the weights of the model, the training configuration, and the state of the optimizer. See https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model Note: This is being built into AutoKeras as ImageClassifier().export_keras_model()","title":"How to export keras models?"},{"location":"start/#how-to-visualize-keras-models","text":"This is not specific to AutoKeras, however, the following will generate a .PNG visualization of the best model found by AutoKeras: from keras.models import load_model model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it. from keras.utils import plot_model plot_model(model, to_file='my_model.png')","title":"How to visualize keras models?"},{"location":"start/#how-to-visualize-the-best-selected-architecture","text":"While trying to create a model, let's say an Image classifier on MNIST, there is a facility for the user to visualize a .PDF depiction of the best architecture that was chosen by autokeras, after model training is complete. Prerequisites : 1) graphviz must be installed in your system. Refer Installation Guide 2) Additionally, also install \"graphviz\" python package using pip / conda pip : pip install graphviz conda : conda install -c conda-forge python-graphviz If the above installations are complete, proceed with the following steps : Step 1 : Specify a path before starting your model training clf = ImageClassifier(path=\"~/automodels/\",verbose=True, augment=False) # Give a custom path of your choice clf.fit(x_train, y_train, time_limit=30 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) Step 2 : After the model training is complete, run examples/visualize.py , whilst passing the same path as parameter if __name__ == '__main__': visualize('~/automodels/')","title":"How to visualize the best selected architecture ?"},{"location":"temp/bayesian/","text":"layer_distance The distance between two layers. layers_distance The distance between the layers of two neural networks. skip_connection_distance The distance between two skip-connections. skip_connections_distance The distance between the skip-connections of two neural networks. edit_distance The distance between two neural networks. Args: x: An instance of NetworkDescriptor. y: An instance of NetworkDescriptor Returns edit_distance_matrix Calculate the edit distance. Args train_x : A list of neural architectures. train_y : A list of neural architectures. Returns vector_distance The Euclidean distance between two vectors. bourgain_embedding_matrix Use Bourgain algorithm to embed the neural architectures based on their edit-distance. Args distance_matrix : A matrix of edit-distances. Returns contain Check if the target descriptor is in the descriptors. IncrementalGaussianProcess Gaussian process regressor. Attributes alpha : A hyperparameter. fit Fit the regressor with more data. Args train_x : A list of NetworkDescriptor. train_y : A list of metric values. incremental_fit Incrementally fit the regressor. first_fit Fit the regressor for the first time. predict Predict the result. Args train_x : A list of NetworkDescriptor. Returns y_mean : The predicted mean. y_std : The predicted standard deviation. BayesianOptimizer A Bayesian optimizer for neural architectures. Attributes searcher : The Searcher which is calling the Bayesian optimizer. t_min : The minimum temperature for simulated annealing. metric : An instance of the Metric subclasses. gpr : A GaussianProcessRegressor for bayesian optimization. beta : The beta in acquisition function. (refer to our paper) search_tree : The network morphism search tree. fit Fit the optimizer with new architectures and performances. Args x_queue : A list of NetworkDescriptor. y_queue : A list of metric values. generate Generate new architecture. Args descriptors : All the searched neural architectures. timeout : An integer. The time limit in seconds. multiprocessing_queue : the Queue for multiprocessing return value. Returns graph : An instance of Graph. A morphed neural network with weights. father_id : The father node ID in the search tree. Elem Elements to be sorted according to metric value. ReverseElem Elements to be reversely sorted according to metric value. SearchTree The network morphism search tree. get_dict A recursive function to return the content of the tree in a dict.","title":"bayesian"},{"location":"temp/bayesian/#layer_distance","text":"The distance between two layers.","title":"layer_distance"},{"location":"temp/bayesian/#layers_distance","text":"The distance between the layers of two neural networks.","title":"layers_distance"},{"location":"temp/bayesian/#skip_connection_distance","text":"The distance between two skip-connections.","title":"skip_connection_distance"},{"location":"temp/bayesian/#skip_connections_distance","text":"The distance between the skip-connections of two neural networks.","title":"skip_connections_distance"},{"location":"temp/bayesian/#edit_distance","text":"The distance between two neural networks. Args: x: An instance of NetworkDescriptor. y: An instance of NetworkDescriptor","title":"edit_distance"},{"location":"temp/bayesian/#returns","text":"","title":"Returns"},{"location":"temp/bayesian/#edit_distance_matrix","text":"Calculate the edit distance.","title":"edit_distance_matrix"},{"location":"temp/bayesian/#args","text":"train_x : A list of neural architectures. train_y : A list of neural architectures.","title":"Args"},{"location":"temp/bayesian/#returns_1","text":"","title":"Returns"},{"location":"temp/bayesian/#vector_distance","text":"The Euclidean distance between two vectors.","title":"vector_distance"},{"location":"temp/bayesian/#bourgain_embedding_matrix","text":"Use Bourgain algorithm to embed the neural architectures based on their edit-distance.","title":"bourgain_embedding_matrix"},{"location":"temp/bayesian/#args_1","text":"distance_matrix : A matrix of edit-distances.","title":"Args"},{"location":"temp/bayesian/#returns_2","text":"","title":"Returns"},{"location":"temp/bayesian/#contain","text":"Check if the target descriptor is in the descriptors.","title":"contain"},{"location":"temp/bayesian/#incrementalgaussianprocess","text":"Gaussian process regressor.","title":"IncrementalGaussianProcess"},{"location":"temp/bayesian/#attributes","text":"alpha : A hyperparameter.","title":"Attributes"},{"location":"temp/bayesian/#fit","text":"Fit the regressor with more data.","title":"fit"},{"location":"temp/bayesian/#args_2","text":"train_x : A list of NetworkDescriptor. train_y : A list of metric values.","title":"Args"},{"location":"temp/bayesian/#incremental_fit","text":"Incrementally fit the regressor.","title":"incremental_fit"},{"location":"temp/bayesian/#first_fit","text":"Fit the regressor for the first time.","title":"first_fit"},{"location":"temp/bayesian/#predict","text":"Predict the result.","title":"predict"},{"location":"temp/bayesian/#args_3","text":"train_x : A list of NetworkDescriptor.","title":"Args"},{"location":"temp/bayesian/#returns_3","text":"y_mean : The predicted mean. y_std : The predicted standard deviation.","title":"Returns"},{"location":"temp/bayesian/#bayesianoptimizer","text":"A Bayesian optimizer for neural architectures.","title":"BayesianOptimizer"},{"location":"temp/bayesian/#attributes_1","text":"searcher : The Searcher which is calling the Bayesian optimizer. t_min : The minimum temperature for simulated annealing. metric : An instance of the Metric subclasses. gpr : A GaussianProcessRegressor for bayesian optimization. beta : The beta in acquisition function. (refer to our paper) search_tree : The network morphism search tree.","title":"Attributes"},{"location":"temp/bayesian/#fit_1","text":"Fit the optimizer with new architectures and performances.","title":"fit"},{"location":"temp/bayesian/#args_4","text":"x_queue : A list of NetworkDescriptor. y_queue : A list of metric values.","title":"Args"},{"location":"temp/bayesian/#generate","text":"Generate new architecture.","title":"generate"},{"location":"temp/bayesian/#args_5","text":"descriptors : All the searched neural architectures. timeout : An integer. The time limit in seconds. multiprocessing_queue : the Queue for multiprocessing return value.","title":"Args"},{"location":"temp/bayesian/#returns_4","text":"graph : An instance of Graph. A morphed neural network with weights. father_id : The father node ID in the search tree.","title":"Returns"},{"location":"temp/bayesian/#elem","text":"Elements to be sorted according to metric value.","title":"Elem"},{"location":"temp/bayesian/#reverseelem","text":"Elements to be reversely sorted according to metric value.","title":"ReverseElem"},{"location":"temp/bayesian/#searchtree","text":"The network morphism search tree.","title":"SearchTree"},{"location":"temp/bayesian/#get_dict","text":"A recursive function to return the content of the tree in a dict.","title":"get_dict"},{"location":"temp/constant/","text":"","title":"Constant"},{"location":"temp/contribute/","text":"Contributing Guide Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. The type of contribution we would be most happy to see is new task modules, e.g. TextClassifier, VideoClassifier. Implement New Task Modules A task module is a comparatively separate module which can handle a specify task. For example, ImageClassifier is the only task module we have for now. The list of task modules we are seeking is all the issues with label \" new task module \". The new task module should be submitted by pull request from the first day you start to develop the module. Make sure your pull request follow the Pull Request Guideline . You can pick any one of them which has not been assigned to anybody yet. If you pick some of the modules which has already been assigned to someone, then we will conduct a thorough evaluation on the benchmark datasets and some preserved datasets. The one performs better in the evaluation will be merged. In general, all new task module should inherit their objects from the Supervised class in autokeras/supervised.py . Reach out to us if you feel there is a special requirement. For every new feature, a new directory should be created inside the /autokeras directory, e.g. text_classifier. All the code contributed should be within the directory. You may put a README.md file in your directory to describe your work. The details of the functions to inherit is in the documentation of autokeras/supervised.py Please also read Code Style Guide , Documentation Guide , Reusable Code Guide , and Testing Guide to ensure your merge request meet our requirements. Other Contributions There are many other ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows. Submit Feedback The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels. Fix Bugs: You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements. Implement Features You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements. Write Documentation The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements. Pull Request Guide Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokeras repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokeras repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now. Code Style Guide This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation. Documentation Guide: The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible. Docstring All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide . Tutorial You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory. Readme File You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use. Testing Guide Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged. Developer Tools Guide We highly recommend you to use Pycharm and virtualenvwrapper . Pycharm Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection. Virtualenvwrapper Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter . Reusable Code Guide You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend. ModelTrainer autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other. Main Contributor List We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Contributing Guide"},{"location":"temp/contribute/#contributing-guide","text":"Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. The type of contribution we would be most happy to see is new task modules, e.g. TextClassifier, VideoClassifier.","title":"Contributing Guide"},{"location":"temp/contribute/#implement-new-task-modules","text":"A task module is a comparatively separate module which can handle a specify task. For example, ImageClassifier is the only task module we have for now. The list of task modules we are seeking is all the issues with label \" new task module \". The new task module should be submitted by pull request from the first day you start to develop the module. Make sure your pull request follow the Pull Request Guideline . You can pick any one of them which has not been assigned to anybody yet. If you pick some of the modules which has already been assigned to someone, then we will conduct a thorough evaluation on the benchmark datasets and some preserved datasets. The one performs better in the evaluation will be merged. In general, all new task module should inherit their objects from the Supervised class in autokeras/supervised.py . Reach out to us if you feel there is a special requirement. For every new feature, a new directory should be created inside the /autokeras directory, e.g. text_classifier. All the code contributed should be within the directory. You may put a README.md file in your directory to describe your work. The details of the functions to inherit is in the documentation of autokeras/supervised.py Please also read Code Style Guide , Documentation Guide , Reusable Code Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement New Task Modules"},{"location":"temp/contribute/#other-contributions","text":"There are many other ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows.","title":"Other Contributions"},{"location":"temp/contribute/#submit-feedback","text":"The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels.","title":"Submit Feedback"},{"location":"temp/contribute/#fix-bugs","text":"You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements.","title":"Fix Bugs:"},{"location":"temp/contribute/#implement-features","text":"You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement Features"},{"location":"temp/contribute/#write-documentation","text":"The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements.","title":"Write Documentation"},{"location":"temp/contribute/#pull-request-guide","text":"Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokeras repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokeras repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now.","title":"Pull Request Guide"},{"location":"temp/contribute/#code-style-guide","text":"This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation.","title":"Code Style Guide"},{"location":"temp/contribute/#documentation-guide","text":"The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible.","title":"Documentation Guide:"},{"location":"temp/contribute/#docstring","text":"All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide .","title":"Docstring"},{"location":"temp/contribute/#tutorial","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory.","title":"Tutorial"},{"location":"temp/contribute/#readme-file","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use.","title":"Readme File"},{"location":"temp/contribute/#testing-guide","text":"Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged.","title":"Testing Guide"},{"location":"temp/contribute/#developer-tools-guide","text":"We highly recommend you to use Pycharm and virtualenvwrapper .","title":"Developer Tools Guide"},{"location":"temp/contribute/#pycharm","text":"Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection.","title":"Pycharm"},{"location":"temp/contribute/#virtualenvwrapper","text":"Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter .","title":"Virtualenvwrapper"},{"location":"temp/contribute/#reusable-code-guide","text":"You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend.","title":"Reusable Code Guide"},{"location":"temp/contribute/#modeltrainer","text":"autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other.","title":"ModelTrainer"},{"location":"temp/contribute/#main-contributor-list","text":"We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Main Contributor List"},{"location":"temp/face_detection_pretrained/","text":"","title":"Face detection pretrained"},{"location":"temp/gan/","text":"DCGAN Deep Convolution Generative Adversary Network init Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation. fit Train only Args x_train : ndarray contained the training data","title":"Gan"},{"location":"temp/gan/#dcgan","text":"Deep Convolution Generative Adversary Network","title":"DCGAN"},{"location":"temp/gan/#init","text":"Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation.","title":"init"},{"location":"temp/gan/#fit","text":"Train only","title":"fit"},{"location":"temp/gan/#args","text":"x_train : ndarray contained the training data","title":"Args"},{"location":"temp/generator/","text":"NetworkGenerator The base class for generating a network. It can be used to generate a CNN or Multi-Layer Perceptron. Attributes n_output_node : Number of output nodes in the network. input_shape : A tuple to represent the input shape. init Initialize the instance. Sets the parameters n_output_node and input_shape for the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. CnnGenerator A class to generate CNN. Attributes n_dim : len(self.input_shape) - 1 conv : A class that represents (n_dim-1) dimensional convolution. dropout : A class that represents (n_dim-1) dimensional dropout. global_avg_pooling : A class that represents (n_dim-1) dimensional Global Average Pooling. pooling : A class that represents (n_dim-1) dimensional pooling. batch_norm : A class that represents (n_dim-1) dimensional batch normalization. init Initialize the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. generate Generates a CNN. Args model_len : An integer. Number of convolutional layers. model_width : An integer. Number of filters for the convolutional layers. Returns MlpGenerator A class to generate Multi-Layer Perceptron. init Initialize the instance. Args n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. If it is 1D, ensure the value is appended by a comma in the tuple. generate Generates a Multi-Layer Perceptron. Args model_len : An integer. Number of hidden layers. model_width : An integer or a list of integers of length model_len . If it is a list, it represents the number of nodes in each hidden layer. If it is an integer, all hidden layers have nodes equal to this value. Returns","title":"generator"},{"location":"temp/generator/#networkgenerator","text":"The base class for generating a network. It can be used to generate a CNN or Multi-Layer Perceptron.","title":"NetworkGenerator"},{"location":"temp/generator/#attributes","text":"n_output_node : Number of output nodes in the network. input_shape : A tuple to represent the input shape.","title":"Attributes"},{"location":"temp/generator/#init","text":"Initialize the instance. Sets the parameters n_output_node and input_shape for the instance.","title":"init"},{"location":"temp/generator/#args","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network.","title":"Args"},{"location":"temp/generator/#cnngenerator","text":"A class to generate CNN.","title":"CnnGenerator"},{"location":"temp/generator/#attributes_1","text":"n_dim : len(self.input_shape) - 1 conv : A class that represents (n_dim-1) dimensional convolution. dropout : A class that represents (n_dim-1) dimensional dropout. global_avg_pooling : A class that represents (n_dim-1) dimensional Global Average Pooling. pooling : A class that represents (n_dim-1) dimensional pooling. batch_norm : A class that represents (n_dim-1) dimensional batch normalization.","title":"Attributes"},{"location":"temp/generator/#init_1","text":"Initialize the instance.","title":"init"},{"location":"temp/generator/#args_1","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network.","title":"Args"},{"location":"temp/generator/#generate","text":"Generates a CNN.","title":"generate"},{"location":"temp/generator/#args_2","text":"model_len : An integer. Number of convolutional layers. model_width : An integer. Number of filters for the convolutional layers.","title":"Args"},{"location":"temp/generator/#returns","text":"","title":"Returns"},{"location":"temp/generator/#mlpgenerator","text":"A class to generate Multi-Layer Perceptron.","title":"MlpGenerator"},{"location":"temp/generator/#init_2","text":"Initialize the instance.","title":"init"},{"location":"temp/generator/#args_3","text":"n_output_node : An integer. Number of output nodes in the network. input_shape : A tuple. Input shape of the network. If it is 1D, ensure the value is appended by a comma in the tuple.","title":"Args"},{"location":"temp/generator/#generate_1","text":"Generates a Multi-Layer Perceptron.","title":"generate"},{"location":"temp/generator/#args_4","text":"model_len : An integer. Number of hidden layers. model_width : An integer or a list of integers of length model_len . If it is a list, it represents the number of nodes in each hidden layer. If it is an integer, all hidden layers have nodes equal to this value.","title":"Args"},{"location":"temp/generator/#returns_1","text":"","title":"Returns"},{"location":"temp/graph/","text":"NetworkDescriptor A class describing the neural architecture for neural network kernel. It only record the width of convolutional and dense layers, and the skip-connection types and positions. add_skip_connection Add a skip-connection to the descriptor. Args u : Number of convolutional layers before the starting point. v : Number of convolutional layers before the ending point. connection_type : Must be either CONCAT_CONNECT or ADD_CONNECT. Node A class for intermediate output tensor (node) in the Graph. Attributes shape : A tuple describing the shape of the tensor. Graph A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.) Attributes input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. layer_id_to_output_node_ids : A dict instance mapping from layer identifiers to their output nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. n_dim : An integer. If it uses Conv1d, n_dim should be 1. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism. init Initializer for Graph. Args input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. add_layer Add a layer to the Graph. Args layer : An instance of the subclasses of StubLayer in layers.py. input_node_id : An integer. The ID of the input node of the layer. Returns output_node_id : An integer. The ID of the output node of the layer. n_nodes Return the number of nodes in the model. n_layers Return the number of layers in the model. _add_node Add a new node to node_list and give the node an ID. Args node : An instance of Node. Returns node_id : An integer. _add_edge Add a new layer to the graph. The nodes should be created in advance. _redirect_edge Redirect the layer to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same. _replace_layer Replace the layer with a new layer. topological_order Return the topological order of the node IDs from the input node to the output node. _get_pooling_layers Given two node IDs, return all the pooling layers between them. _depth_first_search Search for all the layers and nodes down the path. A recursive function to search all the layers and nodes between the node in the node_list and the node with target_id. _search Search the graph for all the layers to be widened caused by an operation. It is an recursive function with duplication check to avoid deadlock. It searches from a starting node u until the corresponding layers has been widened. Args u : The starting node ID. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add. to_deeper_model Insert a relu-conv-bn block after the target block. Args target_id : A convolutional layer ID. The new block should be inserted after the block. new_layer : An instance of StubLayer subclasses. to_wider_model Widen the last dimension of the output of the pre_layer. Args pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add. _insert_new_layers Insert the new_layers after the node with start_node_id. to_add_skip_model Add a weighted add skip-connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. to_concat_skip_model Add a weighted add concatenate connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. extract_descriptor Extract the the description of the Graph as an instance of NetworkDescriptor. produce_model Build a new torch model based on the current graph. produce_keras_model Build a new keras model based on the current graph. get_main_chain_layers Return a list of layer IDs in the main chain. get_main_chain Returns the main chain node ID list. TorchModel A neural network class using pytorch constructed from an instance of Graph.","title":"graph"},{"location":"temp/graph/#networkdescriptor","text":"A class describing the neural architecture for neural network kernel. It only record the width of convolutional and dense layers, and the skip-connection types and positions.","title":"NetworkDescriptor"},{"location":"temp/graph/#add_skip_connection","text":"Add a skip-connection to the descriptor.","title":"add_skip_connection"},{"location":"temp/graph/#args","text":"u : Number of convolutional layers before the starting point. v : Number of convolutional layers before the ending point. connection_type : Must be either CONCAT_CONNECT or ADD_CONNECT.","title":"Args"},{"location":"temp/graph/#node","text":"A class for intermediate output tensor (node) in the Graph.","title":"Node"},{"location":"temp/graph/#attributes","text":"shape : A tuple describing the shape of the tensor.","title":"Attributes"},{"location":"temp/graph/#graph","text":"A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)","title":"Graph"},{"location":"temp/graph/#attributes_1","text":"input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. layer_id_to_output_node_ids : A dict instance mapping from layer identifiers to their output nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. n_dim : An integer. If it uses Conv1d, n_dim should be 1. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism.","title":"Attributes"},{"location":"temp/graph/#init","text":"Initializer for Graph.","title":"init"},{"location":"temp/graph/#args_1","text":"input_shape : A tuple describing the input tensor shape, not including the number of instances. weighted : A boolean marking if there are actual values in the weights of the layers. Sometime we only need the neural architecture information with a graph. In that case, we do not save the weights to save memory and time.","title":"Args"},{"location":"temp/graph/#add_layer","text":"Add a layer to the Graph.","title":"add_layer"},{"location":"temp/graph/#args_2","text":"layer : An instance of the subclasses of StubLayer in layers.py. input_node_id : An integer. The ID of the input node of the layer.","title":"Args"},{"location":"temp/graph/#returns","text":"output_node_id : An integer. The ID of the output node of the layer.","title":"Returns"},{"location":"temp/graph/#n_nodes","text":"Return the number of nodes in the model.","title":"n_nodes"},{"location":"temp/graph/#n_layers","text":"Return the number of layers in the model.","title":"n_layers"},{"location":"temp/graph/#_add_node","text":"Add a new node to node_list and give the node an ID.","title":"_add_node"},{"location":"temp/graph/#args_3","text":"node : An instance of Node.","title":"Args"},{"location":"temp/graph/#returns_1","text":"node_id : An integer.","title":"Returns"},{"location":"temp/graph/#_add_edge","text":"Add a new layer to the graph. The nodes should be created in advance.","title":"_add_edge"},{"location":"temp/graph/#_redirect_edge","text":"Redirect the layer to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.","title":"_redirect_edge"},{"location":"temp/graph/#_replace_layer","text":"Replace the layer with a new layer.","title":"_replace_layer"},{"location":"temp/graph/#topological_order","text":"Return the topological order of the node IDs from the input node to the output node.","title":"topological_order"},{"location":"temp/graph/#_get_pooling_layers","text":"Given two node IDs, return all the pooling layers between them.","title":"_get_pooling_layers"},{"location":"temp/graph/#_depth_first_search","text":"Search for all the layers and nodes down the path. A recursive function to search all the layers and nodes between the node in the node_list and the node with target_id.","title":"_depth_first_search"},{"location":"temp/graph/#_search","text":"Search the graph for all the layers to be widened caused by an operation. It is an recursive function with duplication check to avoid deadlock. It searches from a starting node u until the corresponding layers has been widened.","title":"_search"},{"location":"temp/graph/#args_4","text":"u : The starting node ID. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#to_deeper_model","text":"Insert a relu-conv-bn block after the target block.","title":"to_deeper_model"},{"location":"temp/graph/#args_5","text":"target_id : A convolutional layer ID. The new block should be inserted after the block. new_layer : An instance of StubLayer subclasses.","title":"Args"},{"location":"temp/graph/#to_wider_model","text":"Widen the last dimension of the output of the pre_layer.","title":"to_wider_model"},{"location":"temp/graph/#args_6","text":"pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#_insert_new_layers","text":"Insert the new_layers after the node with start_node_id.","title":"_insert_new_layers"},{"location":"temp/graph/#to_add_skip_model","text":"Add a weighted add skip-connection from after start node to end node.","title":"to_add_skip_model"},{"location":"temp/graph/#args_7","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#to_concat_skip_model","text":"Add a weighted add concatenate connection from after start node to end node.","title":"to_concat_skip_model"},{"location":"temp/graph/#args_8","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#extract_descriptor","text":"Extract the the description of the Graph as an instance of NetworkDescriptor.","title":"extract_descriptor"},{"location":"temp/graph/#produce_model","text":"Build a new torch model based on the current graph.","title":"produce_model"},{"location":"temp/graph/#produce_keras_model","text":"Build a new keras model based on the current graph.","title":"produce_keras_model"},{"location":"temp/graph/#get_main_chain_layers","text":"Return a list of layer IDs in the main chain.","title":"get_main_chain_layers"},{"location":"temp/graph/#get_main_chain","text":"Returns the main chain node ID list.","title":"get_main_chain"},{"location":"temp/graph/#torchmodel","text":"A neural network class using pytorch constructed from an instance of Graph.","title":"TorchModel"},{"location":"temp/image_supervised/","text":"read_images Read the images from the path and return their numpy.ndarray instance. Return a numpy.ndarray instance containing the training data. Args img_file_names : List containing images names. images_dir_path : Path to the directory containing images. load_image_dataset Load images from the files and labels from a csv file. Second, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path . Args csv_file_path : CSV file path. images_path : Path where images exist. Returns x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : The labels. ImageSupervised Abstract image supervised class. Attributes path : A path to the directory to save the classifier as well as intermediate results. cnn : CNN module from net_module.py. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. searcher_args : A dictionary containing the parameters for the searcher's init function. resize_height : resize image height. resize_width : resize image width. init Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args: verbose: A boolean of whether the search process will be printed to stdout. path: A string. The path to a directory, where the intermediate results are saved. resume: A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args: A dictionary containing the parameters for the searcher's init function. augment: A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. export_autokeras_model Creates and Exports the AutoKeras model to the given filename. ImageClassifier ImageClassifier class. It is used for image classification. It searches convolutional neural network architectures for the best configuration for the image dataset. ImageClassifier1D ImageClassifier1D class. It is used for 1D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. ImageClassifier3D ImageClassifier3D class. It is used for 3D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. ImageRegressor ImageRegressor class. It is used for image regression. It searches convolutional neural network architectures for the best configuration for the image dataset. ImageRegressor1D ImageRegressor1D class. It is used for 1D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. ImageRegressor3D ImageRegressor3D class. It is used for 3D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset. PortableImageSupervised init Initialize the instance. Args: graph: The graph form of the learned model predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test .","title":"image_supervised"},{"location":"temp/image_supervised/#read_images","text":"Read the images from the path and return their numpy.ndarray instance. Return a numpy.ndarray instance containing the training data.","title":"read_images"},{"location":"temp/image_supervised/#args","text":"img_file_names : List containing images names. images_dir_path : Path to the directory containing images.","title":"Args"},{"location":"temp/image_supervised/#load_image_dataset","text":"Load images from the files and labels from a csv file. Second, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path .","title":"load_image_dataset"},{"location":"temp/image_supervised/#args_1","text":"csv_file_path : CSV file path. images_path : Path where images exist.","title":"Args"},{"location":"temp/image_supervised/#returns","text":"x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : The labels.","title":"Returns"},{"location":"temp/image_supervised/#imagesupervised","text":"Abstract image supervised class.","title":"ImageSupervised"},{"location":"temp/image_supervised/#attributes","text":"path : A path to the directory to save the classifier as well as intermediate results. cnn : CNN module from net_module.py. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. searcher_args : A dictionary containing the parameters for the searcher's init function. resize_height : resize image height. resize_width : resize image width.","title":"Attributes"},{"location":"temp/image_supervised/#init","text":"Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args: verbose: A boolean of whether the search process will be printed to stdout. path: A string. The path to a directory, where the intermediate results are saved. resume: A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args: A dictionary containing the parameters for the searcher's init function. augment: A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default.","title":"init"},{"location":"temp/image_supervised/#export_autokeras_model","text":"Creates and Exports the AutoKeras model to the given filename.","title":"export_autokeras_model"},{"location":"temp/image_supervised/#imageclassifier","text":"ImageClassifier class. It is used for image classification. It searches convolutional neural network architectures for the best configuration for the image dataset.","title":"ImageClassifier"},{"location":"temp/image_supervised/#imageclassifier1d","text":"ImageClassifier1D class. It is used for 1D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageClassifier1D"},{"location":"temp/image_supervised/#imageclassifier3d","text":"ImageClassifier3D class. It is used for 3D image classification. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageClassifier3D"},{"location":"temp/image_supervised/#imageregressor","text":"ImageRegressor class. It is used for image regression. It searches convolutional neural network architectures for the best configuration for the image dataset.","title":"ImageRegressor"},{"location":"temp/image_supervised/#imageregressor1d","text":"ImageRegressor1D class. It is used for 1D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageRegressor1D"},{"location":"temp/image_supervised/#imageregressor3d","text":"ImageRegressor3D class. It is used for 3D image regression. It searches convolutional neural network architectures for the best configuration for the 1D image dataset.","title":"ImageRegressor3D"},{"location":"temp/image_supervised/#portableimagesupervised","text":"","title":"PortableImageSupervised"},{"location":"temp/image_supervised/#init_1","text":"Initialize the instance. Args: graph: The graph form of the learned model","title":"init"},{"location":"temp/image_supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/image_supervised/#args_2","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/image_supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/image_supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/layer_transformer/","text":"","title":"Layer transformer"},{"location":"temp/layers/","text":"","title":"Layers"},{"location":"temp/loss_function/","text":"","title":"Loss function"},{"location":"temp/metric/","text":"","title":"Metric"},{"location":"temp/model_trainer/","text":"ModelTrainerBase A base class all model trainers will inherit from. Attributes device : A string. Indicating the device to use. 'cuda' or 'cpu'. train_loader : Training data wrapped in batches in Pytorch Dataloader. test_loader : Testing data wrapped in batches in Pytorch Dataloader. loss_function : A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. metric : It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are, all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose : Verbosity mode. train_model Train the model. Args max_iter_num : int, maximum numer of iteration max_no_improvement_num : after max_no_improvement_num, if the model still makes no improvement, finish training. ModelTrainer A class that is used to train the model. This class can train a Pytorch model with the given data loaders. The metric, loss_function, and model must be compatible with each other. Please see the details in the Attributes. Attributes temp_model_path : Specify the path where temp model should be stored. model : An instance of Pytorch Module. The model that will be trained. early_stop : An instance of class EarlyStop. optimizer : The optimizer is chosen to use the Pytorch Adam optimizer. current_epoch : Record the current epoch. train_model Train the model. Train the model with max_iter_num or max_no_improvement_num is met. Args max_iter_num : An integer. The maximum number of epochs to train the model. The training will stop when this number is reached. max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease. The training will stop when this number is reached. Returns _train Where the actual train proceed. _test Function for evaluation. GANModelTrainer A ModelTrainer especially for the GAN. Attributes d_model : A discriminator model. g_model : A generator model. out_f : Out file. out_size : Size of the output image. optimizer_d : Optimizer for discriminator. optimizer_g : Optimizer for generator. init Initialize the GANModelTrainer. Args g_model : The generator model to be trained. d_model : The discriminator model to be trained. train_data : the training data. loss_function : The loss function for both discriminator and generator. verbose : Whether to output the system output. gen_training_result : Whether to generate the intermediate result while training. _train Perform the actual train. EarlyStop A class check for early stop condition. Attributes training_losses : Record all the training loss. minimum_loss : The minimum loss we achieve so far. Used to compared to determine no improvement condition. no_improvement_count : Current no improvement count. _max_no_improvement_num : The maximum number specified. _done : Whether condition met. _min_loss_dec : A threshold for loss improvement. on_train_begin Initiate the early stop condition. Call on every time the training iteration begins. on_epoch_end Check the early stop condition. Call on every time the training iteration end. Args loss : The loss function achieved by the epoch. Returns","title":"model_trainer"},{"location":"temp/model_trainer/#modeltrainerbase","text":"A base class all model trainers will inherit from.","title":"ModelTrainerBase"},{"location":"temp/model_trainer/#attributes","text":"device : A string. Indicating the device to use. 'cuda' or 'cpu'. train_loader : Training data wrapped in batches in Pytorch Dataloader. test_loader : Testing data wrapped in batches in Pytorch Dataloader. loss_function : A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. metric : It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are, all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose : Verbosity mode.","title":"Attributes"},{"location":"temp/model_trainer/#train_model","text":"Train the model.","title":"train_model"},{"location":"temp/model_trainer/#args","text":"max_iter_num : int, maximum numer of iteration max_no_improvement_num : after max_no_improvement_num, if the model still makes no improvement, finish training.","title":"Args"},{"location":"temp/model_trainer/#modeltrainer","text":"A class that is used to train the model. This class can train a Pytorch model with the given data loaders. The metric, loss_function, and model must be compatible with each other. Please see the details in the Attributes.","title":"ModelTrainer"},{"location":"temp/model_trainer/#attributes_1","text":"temp_model_path : Specify the path where temp model should be stored. model : An instance of Pytorch Module. The model that will be trained. early_stop : An instance of class EarlyStop. optimizer : The optimizer is chosen to use the Pytorch Adam optimizer. current_epoch : Record the current epoch.","title":"Attributes"},{"location":"temp/model_trainer/#train_model_1","text":"Train the model. Train the model with max_iter_num or max_no_improvement_num is met.","title":"train_model"},{"location":"temp/model_trainer/#args_1","text":"max_iter_num : An integer. The maximum number of epochs to train the model. The training will stop when this number is reached. max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease. The training will stop when this number is reached.","title":"Args"},{"location":"temp/model_trainer/#returns","text":"","title":"Returns"},{"location":"temp/model_trainer/#_train","text":"Where the actual train proceed.","title":"_train"},{"location":"temp/model_trainer/#_test","text":"Function for evaluation.","title":"_test"},{"location":"temp/model_trainer/#ganmodeltrainer","text":"A ModelTrainer especially for the GAN.","title":"GANModelTrainer"},{"location":"temp/model_trainer/#attributes_2","text":"d_model : A discriminator model. g_model : A generator model. out_f : Out file. out_size : Size of the output image. optimizer_d : Optimizer for discriminator. optimizer_g : Optimizer for generator.","title":"Attributes"},{"location":"temp/model_trainer/#init","text":"Initialize the GANModelTrainer.","title":"init"},{"location":"temp/model_trainer/#args_2","text":"g_model : The generator model to be trained. d_model : The discriminator model to be trained. train_data : the training data. loss_function : The loss function for both discriminator and generator. verbose : Whether to output the system output. gen_training_result : Whether to generate the intermediate result while training.","title":"Args"},{"location":"temp/model_trainer/#_train_1","text":"Perform the actual train.","title":"_train"},{"location":"temp/model_trainer/#earlystop","text":"A class check for early stop condition.","title":"EarlyStop"},{"location":"temp/model_trainer/#attributes_3","text":"training_losses : Record all the training loss. minimum_loss : The minimum loss we achieve so far. Used to compared to determine no improvement condition. no_improvement_count : Current no improvement count. _max_no_improvement_num : The maximum number specified. _done : Whether condition met. _min_loss_dec : A threshold for loss improvement.","title":"Attributes"},{"location":"temp/model_trainer/#on_train_begin","text":"Initiate the early stop condition. Call on every time the training iteration begins.","title":"on_train_begin"},{"location":"temp/model_trainer/#on_epoch_end","text":"Check the early stop condition. Call on every time the training iteration end.","title":"on_epoch_end"},{"location":"temp/model_trainer/#args_3","text":"loss : The loss function achieved by the epoch.","title":"Args"},{"location":"temp/model_trainer/#returns_1","text":"","title":"Returns"},{"location":"temp/net_module/","text":"NetworkModule Class to create a network module. Attributes loss : A function taking two parameters, the predictions and the ground truth. metric : An instance of the Metric subclasses. searcher_args : A dictionary containing the parameters for the searcher's init function. searcher : An instance of the Searcher class. path : A string. The path to the directory to save the searcher. verbose : A boolean. Setting it to true prints to stdout. generators : A list of instances of the NetworkGenerator class or its subclasses. fit Search the best network. Args n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). train_data : A PyTorch DataLoader instance representing the training data. test_data : A PyTorch DataLoader instance representing the testing data. time_limit : A integer value represents the time limit on searching for models. final_fit Final training after found the best architecture. Args trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. train_data : A DataLoader instance representing the training data. test_data : A DataLoader instance representing the testing data. CnnModule Class to create a CNN module. MlpModule Class to create an MLP module.","title":"Net module"},{"location":"temp/net_module/#networkmodule","text":"Class to create a network module.","title":"NetworkModule"},{"location":"temp/net_module/#attributes","text":"loss : A function taking two parameters, the predictions and the ground truth. metric : An instance of the Metric subclasses. searcher_args : A dictionary containing the parameters for the searcher's init function. searcher : An instance of the Searcher class. path : A string. The path to the directory to save the searcher. verbose : A boolean. Setting it to true prints to stdout. generators : A list of instances of the NetworkGenerator class or its subclasses.","title":"Attributes"},{"location":"temp/net_module/#fit","text":"Search the best network.","title":"fit"},{"location":"temp/net_module/#args","text":"n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1). train_data : A PyTorch DataLoader instance representing the training data. test_data : A PyTorch DataLoader instance representing the testing data. time_limit : A integer value represents the time limit on searching for models.","title":"Args"},{"location":"temp/net_module/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/net_module/#args_1","text":"trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. train_data : A DataLoader instance representing the training data. test_data : A DataLoader instance representing the testing data.","title":"Args"},{"location":"temp/net_module/#cnnmodule","text":"Class to create a CNN module.","title":"CnnModule"},{"location":"temp/net_module/#mlpmodule","text":"Class to create an MLP module.","title":"MlpModule"},{"location":"temp/net_transformer/","text":"","title":"Net transformer"},{"location":"temp/preprocessor/","text":"OneHotEncoder A class that can format data. This class provides ways to transform data's classification label into vector. Attributes data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label. init Initialize a OneHotEncoder fit Create mapping from label to vector, and vector to label. transform Get vector for every element in the data array. inverse_transform Get label for every element in data. Cutout Randomly mask out one or more patches from an image. Args n_holes (int) : Number of patches to cut out of each image. length (int) : The length (in pixels) of each square patch. call Perform the actual transformation. Args img (Tensor) : Tensor image of size (C, H, W). Returns Tensor : Image with n_holes of dimension length x length cut out of it. DataTransformer A superclass for all the DataTransformer. transform_train Transform the training data and get the DataLoader class. Args data : x. targets : y. batch_size : the batch size. Returns dataloader : A torch.DataLoader class to represent the transformed data. transform_test Transform the training data and get the DataLoader class. Args data : x. targets : y. batch_size : the batch size. Returns dataloader : A torch.DataLoader class to represent the transformed data. TextDataTransformer A DataTransformer class for the text data. transform_train Transform the training dataset. transform_test Transform the testing dataset. ImageDataTransformer Perform basic image transformation and augmentation. Attributes max_val : the maximum value of all data. mean : the mean value. std : the standard deviation. augment : whether to perform augmentation on data. transform_train Transform the training data, perform random cropping data augmentation and basic random flip augmentation. Args data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of training set. Returns transform_test Transform the test data, perform normalization. Args data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of test set. Returns _transform Perform the actual transformation. Args compose_list : a list of transforming operation. data : x. targets : y. Returns MultiTransformDataset A class incorporate all transform method into a torch.Dataset class. BatchDataset A torch.Dataset class that can read data batch by batch.","title":"preprocessor"},{"location":"temp/preprocessor/#onehotencoder","text":"A class that can format data. This class provides ways to transform data's classification label into vector.","title":"OneHotEncoder"},{"location":"temp/preprocessor/#attributes","text":"data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label.","title":"Attributes"},{"location":"temp/preprocessor/#init","text":"Initialize a OneHotEncoder","title":"init"},{"location":"temp/preprocessor/#fit","text":"Create mapping from label to vector, and vector to label.","title":"fit"},{"location":"temp/preprocessor/#transform","text":"Get vector for every element in the data array.","title":"transform"},{"location":"temp/preprocessor/#inverse_transform","text":"Get label for every element in data.","title":"inverse_transform"},{"location":"temp/preprocessor/#cutout","text":"Randomly mask out one or more patches from an image.","title":"Cutout"},{"location":"temp/preprocessor/#args","text":"n_holes (int) : Number of patches to cut out of each image. length (int) : The length (in pixels) of each square patch.","title":"Args"},{"location":"temp/preprocessor/#call","text":"Perform the actual transformation.","title":"call"},{"location":"temp/preprocessor/#args_1","text":"img (Tensor) : Tensor image of size (C, H, W).","title":"Args"},{"location":"temp/preprocessor/#returns","text":"Tensor : Image with n_holes of dimension length x length cut out of it.","title":"Returns"},{"location":"temp/preprocessor/#datatransformer","text":"A superclass for all the DataTransformer.","title":"DataTransformer"},{"location":"temp/preprocessor/#transform_train","text":"Transform the training data and get the DataLoader class.","title":"transform_train"},{"location":"temp/preprocessor/#args_2","text":"data : x. targets : y. batch_size : the batch size.","title":"Args"},{"location":"temp/preprocessor/#returns_1","text":"dataloader : A torch.DataLoader class to represent the transformed data.","title":"Returns"},{"location":"temp/preprocessor/#transform_test","text":"Transform the training data and get the DataLoader class.","title":"transform_test"},{"location":"temp/preprocessor/#args_3","text":"data : x. targets : y. batch_size : the batch size.","title":"Args"},{"location":"temp/preprocessor/#returns_2","text":"dataloader : A torch.DataLoader class to represent the transformed data.","title":"Returns"},{"location":"temp/preprocessor/#textdatatransformer","text":"A DataTransformer class for the text data.","title":"TextDataTransformer"},{"location":"temp/preprocessor/#transform_train_1","text":"Transform the training dataset.","title":"transform_train"},{"location":"temp/preprocessor/#transform_test_1","text":"Transform the testing dataset.","title":"transform_test"},{"location":"temp/preprocessor/#imagedatatransformer","text":"Perform basic image transformation and augmentation.","title":"ImageDataTransformer"},{"location":"temp/preprocessor/#attributes_1","text":"max_val : the maximum value of all data. mean : the mean value. std : the standard deviation. augment : whether to perform augmentation on data.","title":"Attributes"},{"location":"temp/preprocessor/#transform_train_2","text":"Transform the training data, perform random cropping data augmentation and basic random flip augmentation.","title":"transform_train"},{"location":"temp/preprocessor/#args_4","text":"data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of training set.","title":"Args"},{"location":"temp/preprocessor/#returns_3","text":"","title":"Returns"},{"location":"temp/preprocessor/#transform_test_2","text":"Transform the test data, perform normalization.","title":"transform_test"},{"location":"temp/preprocessor/#args_5","text":"data : Numpy array. The data to be transformed. batch_size : int batch_size. targets : the target of test set.","title":"Args"},{"location":"temp/preprocessor/#returns_4","text":"","title":"Returns"},{"location":"temp/preprocessor/#_transform","text":"Perform the actual transformation.","title":"_transform"},{"location":"temp/preprocessor/#args_6","text":"compose_list : a list of transforming operation. data : x. targets : y.","title":"Args"},{"location":"temp/preprocessor/#returns_5","text":"","title":"Returns"},{"location":"temp/preprocessor/#multitransformdataset","text":"A class incorporate all transform method into a torch.Dataset class.","title":"MultiTransformDataset"},{"location":"temp/preprocessor/#batchdataset","text":"A torch.Dataset class that can read data batch by batch.","title":"BatchDataset"},{"location":"temp/pretrained/","text":"Pretrained The base class for all pretrained task. Attributes: verbose: A boolean value indicating the verbosity mode. init Initialize the instance. load load pretrained model into self.model predict Return predict results for the given image Args: x_predict: An instance of numpy.ndarray containing the testing data. Returns: A numpy.ndarray containing the results.","title":"Pretrained"},{"location":"temp/pretrained/#pretrained","text":"The base class for all pretrained task. Attributes: verbose: A boolean value indicating the verbosity mode.","title":"Pretrained"},{"location":"temp/pretrained/#init","text":"Initialize the instance.","title":"init"},{"location":"temp/pretrained/#load","text":"load pretrained model into self.model","title":"load"},{"location":"temp/pretrained/#predict","text":"Return predict results for the given image Args: x_predict: An instance of numpy.ndarray containing the testing data. Returns: A numpy.ndarray containing the results.","title":"predict"},{"location":"temp/search/","text":"train Train the neural architecture. Searcher Class to search for neural architectures. This class generate new architectures, call the trainer to train it, and update the Bayesian optimizer. Attributes n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. t_min : A float. The minimum temperature during simulated annealing. bo : An instance of BayesianOptimizer. init Initialize the Searcher. Args n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. t_min : A float. The minimum temperature during simulated annealing. add_model Append the information of evaluated architecture to history. init_search Call the generators to generate the initial architectures for the search. search Run the search loop of training, generating and updating once. The function will run the training and generate in parallel. Then it will update the controller. The training is just pop out a graph from the training_queue and train it. The generate will call teh self.generate function. The update will call the self.update function. Args train_data : An instance of DataLoader. test_data : An instance of Dataloader. timeout : An integer, time limit in seconds. update Update the controller with evaluation result of a neural architecture. Args other_info : Anything. In our case it is the father ID in the search tree. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value. model_id : An integer. generate Generate the next neural architecture. Args remaining_time : The remaining time in seconds. multiprocessing_queue : the Queue for multiprocessing return value. Returns other_info : Anything to be saved in the training queue together with the architecture. generated_graph : An instance of Graph.","title":"search"},{"location":"temp/search/#train","text":"Train the neural architecture.","title":"train"},{"location":"temp/search/#searcher","text":"Class to search for neural architectures. This class generate new architectures, call the trainer to train it, and update the Bayesian optimizer.","title":"Searcher"},{"location":"temp/search/#attributes","text":"n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. t_min : A float. The minimum temperature during simulated annealing. bo : An instance of BayesianOptimizer.","title":"Attributes"},{"location":"temp/search/#init","text":"Initialize the Searcher.","title":"init"},{"location":"temp/search/#args","text":"n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. metric : An instance of the Metric subclasses. loss : A function taking two parameters, the predictions and the ground truth. generators : A list of generators used to initialize the search. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. t_min : A float. The minimum temperature during simulated annealing.","title":"Args"},{"location":"temp/search/#add_model","text":"Append the information of evaluated architecture to history.","title":"add_model"},{"location":"temp/search/#init_search","text":"Call the generators to generate the initial architectures for the search.","title":"init_search"},{"location":"temp/search/#search","text":"Run the search loop of training, generating and updating once. The function will run the training and generate in parallel. Then it will update the controller. The training is just pop out a graph from the training_queue and train it. The generate will call teh self.generate function. The update will call the self.update function.","title":"search"},{"location":"temp/search/#args_1","text":"train_data : An instance of DataLoader. test_data : An instance of Dataloader. timeout : An integer, time limit in seconds.","title":"Args"},{"location":"temp/search/#update","text":"Update the controller with evaluation result of a neural architecture.","title":"update"},{"location":"temp/search/#args_2","text":"other_info : Anything. In our case it is the father ID in the search tree. graph : An instance of Graph. The trained neural architecture. metric_value : The final evaluated metric value. model_id : An integer.","title":"Args"},{"location":"temp/search/#generate","text":"Generate the next neural architecture.","title":"generate"},{"location":"temp/search/#args_3","text":"remaining_time : The remaining time in seconds. multiprocessing_queue : the Queue for multiprocessing return value.","title":"Args"},{"location":"temp/search/#returns","text":"other_info : Anything to be saved in the training queue together with the architecture. generated_graph : An instance of Graph.","title":"Returns"},{"location":"temp/supervised/","text":"Supervised The base class for all supervised task. Attributes verbose : A boolean value indicating the verbosity mode. init Initialize the instance. Args verbose : A boolean of whether the search process will be printed to stdout. fit Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train . Args x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds. final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . DeepSupervised init Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args : A dictionary containing the parameters for the searcher's init function. final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. export_keras_model Exports the best Keras model to the given filename. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . PortableClass init Initialize the instance. Args graph : The graph form of the learned model predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test .","title":"supervised"},{"location":"temp/supervised/#supervised","text":"The base class for all supervised task.","title":"Supervised"},{"location":"temp/supervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/supervised/#init","text":"Initialize the instance.","title":"init"},{"location":"temp/supervised/#args","text":"verbose : A boolean of whether the search process will be printed to stdout.","title":"Args"},{"location":"temp/supervised/#fit","text":"Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/supervised/#args_1","text":"x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. time_limit : The time limit for the search in seconds.","title":"Args"},{"location":"temp/supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/supervised/#args_2","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_3","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/supervised/#deepsupervised","text":"","title":"DeepSupervised"},{"location":"temp/supervised/#init_1","text":"Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.","title":"init"},{"location":"temp/supervised/#args_4","text":"verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args : A dictionary containing the parameters for the searcher's init function.","title":"Args"},{"location":"temp/supervised/#final_fit_1","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/supervised/#args_5","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/supervised/#export_keras_model","text":"Exports the best Keras model to the given filename.","title":"export_keras_model"},{"location":"temp/supervised/#predict_1","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_6","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate_1","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/supervised/#portableclass","text":"","title":"PortableClass"},{"location":"temp/supervised/#init_2","text":"Initialize the instance.","title":"init"},{"location":"temp/supervised/#args_7","text":"graph : The graph form of the learned model","title":"Args"},{"location":"temp/supervised/#predict_2","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_8","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns_2","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate_2","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/tabular_preprocessor/","text":"TabularPreprocessor init This constructor is supposed to initialize data members. Use triple quotes for function documentation. fit This function should train the model parameters. Args x : A numpy.ndarray instance containing the training data. y : Training label matrix of dim num_train_samples * num_labels. datainfo : Meta-features of the dataset, which describe encode This function should train the model parameters. Args x : A numpy.ndarray instance containing the training data. y : Training label matrix of dim num_train_samples * num_labels. datainfo : Meta-features of the dataset, which describe","title":"Tabular preprocessor"},{"location":"temp/tabular_preprocessor/#tabularpreprocessor","text":"","title":"TabularPreprocessor"},{"location":"temp/tabular_preprocessor/#init","text":"This constructor is supposed to initialize data members. Use triple quotes for function documentation.","title":"init"},{"location":"temp/tabular_preprocessor/#fit","text":"This function should train the model parameters.","title":"fit"},{"location":"temp/tabular_preprocessor/#args","text":"x : A numpy.ndarray instance containing the training data. y : Training label matrix of dim num_train_samples * num_labels. datainfo : Meta-features of the dataset, which describe","title":"Args"},{"location":"temp/tabular_preprocessor/#encode","text":"This function should train the model parameters.","title":"encode"},{"location":"temp/tabular_preprocessor/#args_1","text":"x : A numpy.ndarray instance containing the training data. y : Training label matrix of dim num_train_samples * num_labels. datainfo : Meta-features of the dataset, which describe","title":"Args"},{"location":"temp/tabular_supervised/","text":"TabularSupervised init This constructor is supposed to initialize data members. Use triple quotes for function documentation. fit This function should train the model parameters. Args x : A numpy.ndarray instance containing the training data. y : Training label matrix of dim num_train_samples * num_labels. inputs X and y are numpy arrays. predict This function should provide predictions of labels on (test) data. The function predict eventually casdn return probabilities or continuous values. TabularRegressor TabularRegressor class. It is used for tabular data regression with lightgbm regressor. TabularClassifier TabularClassifier class. It is used for tabular data classification with lightgbm classifier.","title":"Tabular supervised"},{"location":"temp/tabular_supervised/#tabularsupervised","text":"","title":"TabularSupervised"},{"location":"temp/tabular_supervised/#init","text":"This constructor is supposed to initialize data members. Use triple quotes for function documentation.","title":"init"},{"location":"temp/tabular_supervised/#fit","text":"This function should train the model parameters.","title":"fit"},{"location":"temp/tabular_supervised/#args","text":"x : A numpy.ndarray instance containing the training data. y : Training label matrix of dim num_train_samples * num_labels. inputs X and y are numpy arrays.","title":"Args"},{"location":"temp/tabular_supervised/#predict","text":"This function should provide predictions of labels on (test) data. The function predict eventually casdn return probabilities or continuous values.","title":"predict"},{"location":"temp/tabular_supervised/#tabularregressor","text":"TabularRegressor class. It is used for tabular data regression with lightgbm regressor.","title":"TabularRegressor"},{"location":"temp/tabular_supervised/#tabularclassifier","text":"TabularClassifier class. It is used for tabular data classification with lightgbm classifier.","title":"TabularClassifier"},{"location":"temp/text_preprocessor/","text":"download_pre_train Download pre train file from link in constant.py. Args file_path : String, contains download file path + file name. extract_path : String extract path name. clean_str Tokenization/string cleaning for all string. Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py tokenlize_text Tokenlize text. Vectorize a text corpus by transform each text in texts to a sequence of integers. Args max_num_words : Int, max number of words in the dictionary. max_seq_length : Int, the length of each text sequence, padding if shorter, trim is longer. x_train : List contains text data. Returns x_train : Tokenlized input data. word_index : Dictionary contains word with tokenlized index. read_embedding_index Read pre train file convert to embedding vector. Read the pre trained file into a dictionary where key is the word and value is embedding vector. Args extract_path : String contains pre trained file path. Returns embedding_index : Dictionary contains word with pre trained index. load_pretrain Load the pretrain file into embedding weights. This method will first generate the embedding index and then generate embedding matrix according to the word_index. Args path : String, path to store the pretrain files. word_index : Dictionary contains word with tokenlized index. Returns embedding_matrix : Numpy array as the pretrain model embedding layer weights. processing Processing string array with pretrained vectors. convert an n dimension string array into n * k * m dimension float numpy array. Each k * m array represents a string. k is the input_length which means an upper bound of the string length, for string shorter than k will be pad and longer string will be cropped. m is defined by the pretrained file. Args path : String, path where the pre trained files stored. word_index : Dictionary, contains word with tokenlized index. input_length : Int, an upper bound of the string length. x_train : String array. Returns x_train : Numpy array as processed x_train. text_preprocess This is the text preprocess main method. It takes an raw string, clean it and processing it into tokenlized numpy array.","title":"Text preprocessor"},{"location":"temp/text_preprocessor/#download_pre_train","text":"Download pre train file from link in constant.py.","title":"download_pre_train"},{"location":"temp/text_preprocessor/#args","text":"file_path : String, contains download file path + file name. extract_path : String extract path name.","title":"Args"},{"location":"temp/text_preprocessor/#clean_str","text":"Tokenization/string cleaning for all string. Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py","title":"clean_str"},{"location":"temp/text_preprocessor/#tokenlize_text","text":"Tokenlize text. Vectorize a text corpus by transform each text in texts to a sequence of integers.","title":"tokenlize_text"},{"location":"temp/text_preprocessor/#args_1","text":"max_num_words : Int, max number of words in the dictionary. max_seq_length : Int, the length of each text sequence, padding if shorter, trim is longer. x_train : List contains text data.","title":"Args"},{"location":"temp/text_preprocessor/#returns","text":"x_train : Tokenlized input data. word_index : Dictionary contains word with tokenlized index.","title":"Returns"},{"location":"temp/text_preprocessor/#read_embedding_index","text":"Read pre train file convert to embedding vector. Read the pre trained file into a dictionary where key is the word and value is embedding vector.","title":"read_embedding_index"},{"location":"temp/text_preprocessor/#args_2","text":"extract_path : String contains pre trained file path.","title":"Args"},{"location":"temp/text_preprocessor/#returns_1","text":"embedding_index : Dictionary contains word with pre trained index.","title":"Returns"},{"location":"temp/text_preprocessor/#load_pretrain","text":"Load the pretrain file into embedding weights. This method will first generate the embedding index and then generate embedding matrix according to the word_index.","title":"load_pretrain"},{"location":"temp/text_preprocessor/#args_3","text":"path : String, path to store the pretrain files. word_index : Dictionary contains word with tokenlized index.","title":"Args"},{"location":"temp/text_preprocessor/#returns_2","text":"embedding_matrix : Numpy array as the pretrain model embedding layer weights.","title":"Returns"},{"location":"temp/text_preprocessor/#processing","text":"Processing string array with pretrained vectors. convert an n dimension string array into n * k * m dimension float numpy array. Each k * m array represents a string. k is the input_length which means an upper bound of the string length, for string shorter than k will be pad and longer string will be cropped. m is defined by the pretrained file.","title":"processing"},{"location":"temp/text_preprocessor/#args_4","text":"path : String, path where the pre trained files stored. word_index : Dictionary, contains word with tokenlized index. input_length : Int, an upper bound of the string length. x_train : String array.","title":"Args"},{"location":"temp/text_preprocessor/#returns_3","text":"x_train : Numpy array as processed x_train.","title":"Returns"},{"location":"temp/text_preprocessor/#text_preprocess","text":"This is the text preprocess main method. It takes an raw string, clean it and processing it into tokenlized numpy array.","title":"text_preprocess"},{"location":"temp/text_supervised/","text":"TextSupervised TextClassifier class. Attributes cnn : CNN module from net_module.py. path : A path to the directory to save the classifier as well as intermediate results. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout. init Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args : A dictionary containing the parameters for the searcher's init function. fit Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train . Args x : A numpy.ndarray instance containing the training data. y : A numpy.ndarray instance containing the label of the training data. time_limit : The time limit for the search in seconds. TextRegressor TextRegressor class. It is used for text regression. It searches convolutional neural network architectures for the best configuration for the text dataset.","title":"Text supervised"},{"location":"temp/text_supervised/#textsupervised","text":"TextClassifier class.","title":"TextSupervised"},{"location":"temp/text_supervised/#attributes","text":"cnn : CNN module from net_module.py. path : A path to the directory to save the classifier as well as intermediate results. y_encoder : Label encoder, used in transform_y or inverse_transform_y for encode the label. For example, if one hot encoder needed, y_encoder can be OneHotEncoder. data_transformer : A transformer class to process the data. See example as ImageDataTransformer. verbose : A boolean value indicating the verbosity mode which determines whether the search process will be printed to stdout.","title":"Attributes"},{"location":"temp/text_supervised/#init","text":"Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.","title":"init"},{"location":"temp/text_supervised/#args","text":"verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. searcher_args : A dictionary containing the parameters for the searcher's init function.","title":"Args"},{"location":"temp/text_supervised/#fit","text":"Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/text_supervised/#args_1","text":"x : A numpy.ndarray instance containing the training data. y : A numpy.ndarray instance containing the label of the training data. time_limit : The time limit for the search in seconds.","title":"Args"},{"location":"temp/text_supervised/#textregressor","text":"TextRegressor class. It is used for text regression. It searches convolutional neural network architectures for the best configuration for the text dataset.","title":"TextRegressor"},{"location":"temp/unsupervised/","text":"Unsupervised The base class for all unsupervised task Attributes verbose : A boolean value indicating the verbosity mode. init Args: verbose: A boolean of whether the search process will be printed to stdout. fit Args: x_train: A numpy.ndarray instance containing the training data. generate Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"Unsupervised"},{"location":"temp/unsupervised/#unsupervised","text":"The base class for all unsupervised task","title":"Unsupervised"},{"location":"temp/unsupervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/unsupervised/#init","text":"Args: verbose: A boolean of whether the search process will be printed to stdout.","title":"init"},{"location":"temp/unsupervised/#fit","text":"Args: x_train: A numpy.ndarray instance containing the training data.","title":"fit"},{"location":"temp/unsupervised/#generate","text":"Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"generate"},{"location":"temp/utils/","text":"ensure_dir Create directory if it does not exist. ensure_file_dir Create path if it does not exist. has_file Check if the given path exists. pickle_from_file Load the pickle file from the provided path and returns the object. pickle_to_file Save the pickle file to the specified path. get_device If CUDA is available, use CUDA device, else use CPU device. When choosing from CUDA devices, this function will choose the one with max memory available. rand_temp_folder_generator Create and return a temporary directory with the path name '/temp_dir_name/autokeras' (E:g:- /tmp/autokeras). download_file Download the file specified in file_link and saves it in file_path . download_file_with_extract Download the file specified in file_link , save to file_path and extract to the directory extract_path . verbose_print Print information about the operation performed on father model to obtain current model and father's id. validate_xy Validate x_train 's type and the shape of x_train , y_train . read_csv_file Read the csv file and returns two separate list containing file names and their labels. Args csv_file_path : Path to the CSV file. Returns file_names : List containing files names. file_label : List containing their respective labels. read_image Read the image contained in the provided path image_path . compute_image_resize_params Compute median dimension of all images in data. It used to resize the images later. Number of channels do not change from the original data. Args data : 1-D, 2-D or 3-D images. The Images are expected to have channel last configuration. Returns resize_image_data Resize images to given dimension. Args data : 1-D, 2-D or 3-D images. The Images are expected to have channel last configuration. resize_shape : Image resize dimension. Returns data : Reshaped data. get_system Get the current system environment. If the current system is not supported, raise an exception. Returns","title":"utils"},{"location":"temp/utils/#ensure_dir","text":"Create directory if it does not exist.","title":"ensure_dir"},{"location":"temp/utils/#ensure_file_dir","text":"Create path if it does not exist.","title":"ensure_file_dir"},{"location":"temp/utils/#has_file","text":"Check if the given path exists.","title":"has_file"},{"location":"temp/utils/#pickle_from_file","text":"Load the pickle file from the provided path and returns the object.","title":"pickle_from_file"},{"location":"temp/utils/#pickle_to_file","text":"Save the pickle file to the specified path.","title":"pickle_to_file"},{"location":"temp/utils/#get_device","text":"If CUDA is available, use CUDA device, else use CPU device. When choosing from CUDA devices, this function will choose the one with max memory available.","title":"get_device"},{"location":"temp/utils/#rand_temp_folder_generator","text":"Create and return a temporary directory with the path name '/temp_dir_name/autokeras' (E:g:- /tmp/autokeras).","title":"rand_temp_folder_generator"},{"location":"temp/utils/#download_file","text":"Download the file specified in file_link and saves it in file_path .","title":"download_file"},{"location":"temp/utils/#download_file_with_extract","text":"Download the file specified in file_link , save to file_path and extract to the directory extract_path .","title":"download_file_with_extract"},{"location":"temp/utils/#verbose_print","text":"Print information about the operation performed on father model to obtain current model and father's id.","title":"verbose_print"},{"location":"temp/utils/#validate_xy","text":"Validate x_train 's type and the shape of x_train , y_train .","title":"validate_xy"},{"location":"temp/utils/#read_csv_file","text":"Read the csv file and returns two separate list containing file names and their labels.","title":"read_csv_file"},{"location":"temp/utils/#args","text":"csv_file_path : Path to the CSV file.","title":"Args"},{"location":"temp/utils/#returns","text":"file_names : List containing files names. file_label : List containing their respective labels.","title":"Returns"},{"location":"temp/utils/#read_image","text":"Read the image contained in the provided path image_path .","title":"read_image"},{"location":"temp/utils/#compute_image_resize_params","text":"Compute median dimension of all images in data. It used to resize the images later. Number of channels do not change from the original data.","title":"compute_image_resize_params"},{"location":"temp/utils/#args_1","text":"data : 1-D, 2-D or 3-D images. The Images are expected to have channel last configuration.","title":"Args"},{"location":"temp/utils/#returns_1","text":"","title":"Returns"},{"location":"temp/utils/#resize_image_data","text":"Resize images to given dimension.","title":"resize_image_data"},{"location":"temp/utils/#args_2","text":"data : 1-D, 2-D or 3-D images. The Images are expected to have channel last configuration. resize_shape : Image resize dimension.","title":"Args"},{"location":"temp/utils/#returns_2","text":"data : Reshaped data.","title":"Returns"},{"location":"temp/utils/#get_system","text":"Get the current system environment. If the current system is not supported, raise an exception.","title":"get_system"},{"location":"temp/utils/#returns_3","text":"","title":"Returns"}]}