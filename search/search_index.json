{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Auto-Keras is an open source software library for automated machine learning (AutoML). It is developed by DATA Lab at Texas A&M University and community contributors. The ultimate goal of AutoML is to provide easily accessible deep learning tools to domain experts with limited data science or machine learning background. Auto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models. Installation To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 . Example Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test) Community You can use Gitter to communicate with people who also interested in Auto-Keras. Citing this work If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, } DISCLAIMER Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated. Acknowledgements The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Home"},{"location":"#installation","text":"To install the package, please use the pip installation as follows: pip install autokeras Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"#example","text":"Here is a short example of using the package. import autokeras as ak clf = ak.ImageClassifier() clf.fit(x_train, y_train) results = clf.predict(x_test)","title":"Example"},{"location":"#community","text":"You can use Gitter to communicate with people who also interested in Auto-Keras.","title":"Community"},{"location":"#citing-this-work","text":"If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper: Efficient Neural Architecture Search with Network Morphism. Haifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 . Biblatex entry: @online{jin2018efficient, author = {Haifeng Jin and Qingquan Song and Xia Hu}, title = {Auto-Keras: Efficient Neural Architecture Search with Network Morphism}, date = {2018-06-27}, year = {2018}, eprintclass = {cs.LG}, eprinttype = {arXiv}, eprint = {cs.LG/1806.10282}, }","title":"Citing this work"},{"location":"#disclaimer","text":"Please note that this is a pre-release version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated.","title":"DISCLAIMER"},{"location":"#acknowledgements","text":"The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Acknowledgements"},{"location":"about/","text":"About This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"about/#about","text":"This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"docker/","text":"Auto-Keras Docker Download Auto-Keras Docker image The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras Start Auto-Keras Docker container docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference ) Run application : To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py Example : Let's download the mnist example and run it within the container. Download the example : wget https://raw.githubusercontent.com/jhfjhfj1/autokeras/master/examples/mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Getting Started with Docker"},{"location":"docker/#auto-keras-docker","text":"","title":"Auto-Keras Docker"},{"location":"docker/#download-auto-keras-docker-image","text":"The following command download Auto-Keras docker image to your machine. docker pull garawalid/autokeras","title":"Download Auto-Keras Docker image"},{"location":"docker/#start-auto-keras-docker-container","text":"docker run -it --shm-size 2G garawalid/autokeras /bin/bash In case you need more memory to run the container, change the value of shm-size . ( Docker run reference )","title":"Start Auto-Keras Docker container"},{"location":"docker/#run-application","text":"To run a local script file.py using Auto-Keras within the container, mount the host directory -v hostDir:/app . docker run -it -v hostDir:/app --shm-size 2G garawalid/autokeras python file.py","title":"Run application :"},{"location":"docker/#example","text":"Let's download the mnist example and run it within the container. Download the example : wget https://raw.githubusercontent.com/jhfjhfj1/autokeras/master/examples/mnist.py Run the mnist example : docker run -it -v \"$(pwd)\":/app --shm-size 2G garawalid/autokeras python mnist.py","title":"Example :"},{"location":"start/","text":"Getting Started Installation The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 . Latest Stable Version ( pip installation): You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras Bleeding Edge Version (manual installation): If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install Example We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs. Data with numpy array (.npy) format. If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays. What if your data are raw image files ( e.g. .jpg, .png, .bmp)? You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier . How to export keras models? from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5') This uses the keras function model.save() to export a single HDF5 file containing the architecture of the model, the weights of the model, the training configuration, and the state of the optimizer. See https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model Note: This is being built into AutoKeras as ImageClassifier().export_keras_model() How to visualize keras models? This is not specific to AutoKeras, however, the following will generate a .PNG visualization of the best model found by AutoKeras: from keras.models import load_model model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it. from keras.utils import plot_model plot_model(model, to_file='my_model.png')","title":"Getting Started"},{"location":"start/#getting-started","text":"","title":"Getting Started"},{"location":"start/#installation","text":"The installation of Auto-Keras is the same as other python packages. Note: currently, Auto-Keras is only compatible with: Python 3.6 .","title":"Installation"},{"location":"start/#latest-stable-version-pip-installation","text":"You can run the following pip installation command in your terminal to install the latest stable version. pip install autokeras","title":"Latest Stable Version (pip installation):"},{"location":"start/#bleeding-edge-version-manual-installation","text":"If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install","title":"Bleeding Edge Version (manual installation):"},{"location":"start/#example","text":"We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs.","title":"Example"},{"location":"start/#data-with-numpy-array-npy-format","text":"If the images and the labels are already formatted into numpy arrays, you can from keras.datasets import mnist from autokeras.image_supervised import ImageClassifier if __name__ == '__main__': (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y) In the example above, the images and the labels are already formatted into numpy arrays.","title":"Data with numpy array (.npy) format."},{"location":"start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp","text":"You can use our load_image_dataset function to load the images and their labels as follows. from autokeras.image_supervised import load_image_dataset x_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\", images_path=\"train\") print(x_train.shape) print(y_train.shape) x_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\", images_path=\"test\") print(x_test.shape) print(y_test.shape) The argument csv_file_path is the path to the CSV file containing the image file names and their corresponding labels. Here is an example of the csv file. File Name,Label 00000.jpg,5 00001.jpg,0 00002.jpg,4 00003.jpg,1 00004.jpg,9 00005.jpg,2 00006.jpg,1 ... The second argument images_path is the path to the directory containing all the images with those file names listed in the CSV file. The returned values x_train and y_train are the numpy arrays, which can be directly feed into the fit function of ImageClassifier .","title":"What if your data are raw image files (e.g. .jpg, .png, .bmp)?"},{"location":"start/#how-to-export-keras-models","text":"from autokeras import ImageClassifier clf = ImageClassifier(verbose=True, augment=False) clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5') This uses the keras function model.save() to export a single HDF5 file containing the architecture of the model, the weights of the model, the training configuration, and the state of the optimizer. See https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model Note: This is being built into AutoKeras as ImageClassifier().export_keras_model()","title":"How to export keras models?"},{"location":"start/#how-to-visualize-keras-models","text":"This is not specific to AutoKeras, however, the following will generate a .PNG visualization of the best model found by AutoKeras: from keras.models import load_model model = load_model('my_model.h5') #See 'How to export keras models?' to generate this file before loading it. from keras.utils import plot_model plot_model(model, to_file='my_model.png')","title":"How to visualize keras models?"},{"location":"temp/bayesian/","text":"BayesianOptimizer gpr: A GaussianProcessRegressor for bayesian optimization.","title":"bayesian"},{"location":"temp/bayesian/#bayesianoptimizer","text":"gpr: A GaussianProcessRegressor for bayesian optimization.","title":"BayesianOptimizer"},{"location":"temp/cnn_module/","text":"CnnModule fit Search the best CnnModule. Args n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1) train_data : A PyTorch DataLoader instance represents the training data test_data : A PyTorch DataLoader instance represents the testing data time_limit : A integer value represents the time limit on searching for models. final_fit Final training after found the best architecture. Args trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. train_data : A DataLoader instance representing the training data test_data : A DataLoader instance representing the testing data","title":"Cnn module"},{"location":"temp/cnn_module/#cnnmodule","text":"","title":"CnnModule"},{"location":"temp/cnn_module/#fit","text":"Search the best CnnModule.","title":"fit"},{"location":"temp/cnn_module/#args","text":"n_output_node : A integer value represent the number of output node in the final layer. input_shape : A tuple to express the shape of every train entry. For example, MNIST dataset would be (28,28,1) train_data : A PyTorch DataLoader instance represents the training data test_data : A PyTorch DataLoader instance represents the testing data time_limit : A integer value represents the time limit on searching for models.","title":"Args"},{"location":"temp/cnn_module/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/cnn_module/#args_1","text":"trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. train_data : A DataLoader instance representing the training data test_data : A DataLoader instance representing the testing data","title":"Args"},{"location":"temp/constant/","text":"","title":"Constant"},{"location":"temp/contribute/","text":"Contributing Guide Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. The type of contribution we would be most happy to see is new task modules, e.g. TextClassifier, VideoClassifier. Implement New Task Modules A task module is a comparatively separate module which can handle a specify task. For example, ImageClassifier is the only task module we have for now. The list of task modules we are seeking is all the issues with label \" new task module \". The new task module should be submitted by pull request from the first day you start to develop the module. Make sure your pull request follow the Pull Request Guideline . You can pick any one of them which has not been assigned to anybody yet. If you pick some of the modules which has already been assigned to someone, then we will conduct a thorough evaluation on the benchmark datasets and some preserved datasets. The one performs better in the evaluation will be merged. In general, all new task module should inherit their objects from the Supervised class in autokeras/supervised.py . Reach out to us if you feel there is a special requirement. For every new feature, a new directory should be created inside the /autokeras directory, e.g. text_classifier. All the code contributed should be within the directory. You may put a README.md file in your directory to describe your work. The details of the functions to inherit is in the documentation of autokeras/supervised.py Please also read Code Style Guide , Documentation Guide , Reusable Code Guide , and Testing Guide to ensure your merge request meet our requirements. Other Contributions There are many other ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows. Submit Feedback The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels. Fix Bugs: You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements. Implement Features You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements. Write Documentation The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements. Pull Request Guide Before you submit a pull request, check that it meets these guidelines: Submit the pull request from the first day when you started your development and prefix the title of the pull request with [WIP] Give your pull request title and branch name should contain helpful information summarizing your contribution. Include \"resolves #issue_number\" in the title and the description of the pull request. For the case of bug fixes, at the time of the PR, the test case should fail for the code base in the master branch and pass for the PR code. When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . Checkout from and pull request to the develop branch. If it is a very urgent bug fix, checkout from master and pull request to both master and develop. Code Style Guide This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation. Documentation Guide: The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible. Docstring All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide . Tutorial You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory. Readme File You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use. Testing Guide Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged. Developer Tools Guide We highly recommend you to use Pycharm and virtualenvwrapper . Pycharm Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection. Virtualenvwrapper Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter . Reusable Code Guide You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend. ModelTrainer autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other. Main Contributor List We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Contributing Guide"},{"location":"temp/contribute/#contributing-guide","text":"Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. The type of contribution we would be most happy to see is new task modules, e.g. TextClassifier, VideoClassifier.","title":"Contributing Guide"},{"location":"temp/contribute/#implement-new-task-modules","text":"A task module is a comparatively separate module which can handle a specify task. For example, ImageClassifier is the only task module we have for now. The list of task modules we are seeking is all the issues with label \" new task module \". The new task module should be submitted by pull request from the first day you start to develop the module. Make sure your pull request follow the Pull Request Guideline . You can pick any one of them which has not been assigned to anybody yet. If you pick some of the modules which has already been assigned to someone, then we will conduct a thorough evaluation on the benchmark datasets and some preserved datasets. The one performs better in the evaluation will be merged. In general, all new task module should inherit their objects from the Supervised class in autokeras/supervised.py . Reach out to us if you feel there is a special requirement. For every new feature, a new directory should be created inside the /autokeras directory, e.g. text_classifier. All the code contributed should be within the directory. You may put a README.md file in your directory to describe your work. The details of the functions to inherit is in the documentation of autokeras/supervised.py Please also read Code Style Guide , Documentation Guide , Reusable Code Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement New Task Modules"},{"location":"temp/contribute/#other-contributions","text":"There are many other ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows.","title":"Other Contributions"},{"location":"temp/contribute/#submit-feedback","text":"The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels.","title":"Submit Feedback"},{"location":"temp/contribute/#fix-bugs","text":"You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements.","title":"Fix Bugs:"},{"location":"temp/contribute/#implement-features","text":"You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement Features"},{"location":"temp/contribute/#write-documentation","text":"The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements.","title":"Write Documentation"},{"location":"temp/contribute/#pull-request-guide","text":"Before you submit a pull request, check that it meets these guidelines: Submit the pull request from the first day when you started your development and prefix the title of the pull request with [WIP] Give your pull request title and branch name should contain helpful information summarizing your contribution. Include \"resolves #issue_number\" in the title and the description of the pull request. For the case of bug fixes, at the time of the PR, the test case should fail for the code base in the master branch and pass for the PR code. When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . Checkout from and pull request to the develop branch. If it is a very urgent bug fix, checkout from master and pull request to both master and develop.","title":"Pull Request Guide"},{"location":"temp/contribute/#code-style-guide","text":"This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation.","title":"Code Style Guide"},{"location":"temp/contribute/#documentation-guide","text":"The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible.","title":"Documentation Guide:"},{"location":"temp/contribute/#docstring","text":"All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide .","title":"Docstring"},{"location":"temp/contribute/#tutorial","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory.","title":"Tutorial"},{"location":"temp/contribute/#readme-file","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use.","title":"Readme File"},{"location":"temp/contribute/#testing-guide","text":"Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged.","title":"Testing Guide"},{"location":"temp/contribute/#developer-tools-guide","text":"We highly recommend you to use Pycharm and virtualenvwrapper .","title":"Developer Tools Guide"},{"location":"temp/contribute/#pycharm","text":"Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection.","title":"Pycharm"},{"location":"temp/contribute/#virtualenvwrapper","text":"Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokeras development with virtualenvwrapper, and only install the packages required by autokeras with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter .","title":"Virtualenvwrapper"},{"location":"temp/contribute/#reusable-code-guide","text":"You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend.","title":"Reusable Code Guide"},{"location":"temp/contribute/#modeltrainer","text":"autokeras.model_trainer.ModelTrainer is a class for training Pytorch models. If needed a new metric or loss function other than the ones we have, you can add your own to loss_function.py and metric.py . You can follow its documentation and this example to use it. Make sure your loss function, metric, Pytorch model, and Dataloader are compatible with each other.","title":"ModelTrainer"},{"location":"temp/contribute/#main-contributor-list","text":"We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Main Contributor List"},{"location":"temp/gan/","text":"DCGAN Deep Convolution Generative Adversary Network init Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation. fit Train only Args x_train : ndarray contained the training data","title":"Gan"},{"location":"temp/gan/#dcgan","text":"Deep Convolution Generative Adversary Network","title":"DCGAN"},{"location":"temp/gan/#init","text":"Args: nz: size of the latent z vector ngf: of gen filters in first conv layer ndf: of discrim filters in first conv layer nc: number of input chanel verbose: A boolean of whether the search process will be printed to stdout. gen_training_result: A tuple of (path, size) to denote where to output the intermediate result with size augment: A boolean value indicating whether the data needs augmentation.","title":"init"},{"location":"temp/gan/#fit","text":"Train only","title":"fit"},{"location":"temp/gan/#args","text":"x_train : ndarray contained the training data","title":"Args"},{"location":"temp/generator/","text":"","title":"generator"},{"location":"temp/graph/","text":"Graph A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.) Attributes weighted : A boolean of whether the weights and biases in the neural network should be included in the graph. input_shape : A tuple of integers, which does not include the batch axis. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism. n_nodes Return the number of nodes in the model. n_layers Return the number of layers in the model. _add_node Add node to node list if it is not in node list. _add_edge Add an edge to the graph. _redirect_edge Redirect the edge to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same. _replace_layer Replace the layer with a new layer. topological_order Return the topological order of the node ids. _search Search the graph for widening the layers. Args u : The starting node identifier. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add. to_conv_deeper_model Insert a relu-conv-bn block after the target block. Args target_id : A convolutional layer ID. The new block should be inserted after the block. kernel_size : An integer. The kernel size of the new convolutional layer. to_wider_model Widen the last dimension of the output of the pre_layer. Args pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add. to_dense_deeper_model Insert a dense layer after the target layer. Args target_id : The ID of a dense layer. _conv_block_end_node Get the input node ID of the last layer in the block by layer ID. Return the input node ID of the last layer in the convolutional block. Args layer_id : the convolutional layer ID. to_add_skip_model Add a weighted add skip-connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. to_concat_skip_model Add a weighted add concatenate connection from after start node to end node. Args start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection. produce_model Build a new model based on the current graph. produce_keras_model Build a new keras model based on the current graph.","title":"graph"},{"location":"temp/graph/#graph","text":"A class representing the neural architecture graph of a Keras model. Graph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph. Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)","title":"Graph"},{"location":"temp/graph/#attributes","text":"weighted : A boolean of whether the weights and biases in the neural network should be included in the graph. input_shape : A tuple of integers, which does not include the batch axis. node_list : A list of integers. The indices of the list are the identifiers. layer_list : A list of stub layers. The indices of the list are the identifiers. node_to_id : A dict instance mapping from node integers to their identifiers. layer_to_id : A dict instance mapping from stub layers to their identifiers. layer_id_to_input_node_ids : A dict instance mapping from layer identifiers to their input nodes identifiers. adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is identified by tensor identifiers. In each edge list, the elements are two-element tuples of (tensor identifier, layer identifier). reverse_adj_list : A reverse adjacent list in the same format as adj_list. operation_history : A list saving all the network morphism operations. vis : A dictionary of temporary storage for whether an local operation has been done during the network morphism.","title":"Attributes"},{"location":"temp/graph/#n_nodes","text":"Return the number of nodes in the model.","title":"n_nodes"},{"location":"temp/graph/#n_layers","text":"Return the number of layers in the model.","title":"n_layers"},{"location":"temp/graph/#_add_node","text":"Add node to node list if it is not in node list.","title":"_add_node"},{"location":"temp/graph/#_add_edge","text":"Add an edge to the graph.","title":"_add_edge"},{"location":"temp/graph/#_redirect_edge","text":"Redirect the edge to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.","title":"_redirect_edge"},{"location":"temp/graph/#_replace_layer","text":"Replace the layer with a new layer.","title":"_replace_layer"},{"location":"temp/graph/#topological_order","text":"Return the topological order of the node ids.","title":"topological_order"},{"location":"temp/graph/#_search","text":"Search the graph for widening the layers.","title":"_search"},{"location":"temp/graph/#args","text":"u : The starting node identifier. start_dim : The position to insert the additional dimensions. total_dim : The total number of dimensions the layer has before widening. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#to_conv_deeper_model","text":"Insert a relu-conv-bn block after the target block.","title":"to_conv_deeper_model"},{"location":"temp/graph/#args_1","text":"target_id : A convolutional layer ID. The new block should be inserted after the block. kernel_size : An integer. The kernel size of the new convolutional layer.","title":"Args"},{"location":"temp/graph/#to_wider_model","text":"Widen the last dimension of the output of the pre_layer.","title":"to_wider_model"},{"location":"temp/graph/#args_2","text":"pre_layer_id : The ID of a convolutional layer or dense layer. n_add : The number of dimensions to add.","title":"Args"},{"location":"temp/graph/#to_dense_deeper_model","text":"Insert a dense layer after the target layer.","title":"to_dense_deeper_model"},{"location":"temp/graph/#args_3","text":"target_id : The ID of a dense layer.","title":"Args"},{"location":"temp/graph/#_conv_block_end_node","text":"Get the input node ID of the last layer in the block by layer ID. Return the input node ID of the last layer in the convolutional block.","title":"_conv_block_end_node"},{"location":"temp/graph/#args_4","text":"layer_id : the convolutional layer ID.","title":"Args"},{"location":"temp/graph/#to_add_skip_model","text":"Add a weighted add skip-connection from after start node to end node.","title":"to_add_skip_model"},{"location":"temp/graph/#args_5","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#to_concat_skip_model","text":"Add a weighted add concatenate connection from after start node to end node.","title":"to_concat_skip_model"},{"location":"temp/graph/#args_6","text":"start_id : The convolutional layer ID, after which to start the skip-connection. end_id : The convolutional layer ID, after which to end the skip-connection.","title":"Args"},{"location":"temp/graph/#produce_model","text":"Build a new model based on the current graph.","title":"produce_model"},{"location":"temp/graph/#produce_keras_model","text":"Build a new keras model based on the current graph.","title":"produce_keras_model"},{"location":"temp/image_supervised/","text":"read_images Read the images from the path and return their numpy.ndarray instance. Return a numpy.ndarray instance containing the training data. Args img_file_names : List containing images names. images_dir_path : Path to the directory containing images. load_image_dataset Load images from the files and labels from a csv file. Second, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path . Args csv_file_path : CSV file path. images_path : Path where images exist. Returns x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : The labels. ImageSupervised The image classifier class. It is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset. Attributes path : A path to the directory to save the classifier. y_encoder : An instance of OneHotEncoder for y_train (array of categorical labels). verbose : A boolean value indicating the verbosity mode. searcher_args : A dictionary containing the parameters for the searcher's init function. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. init Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one. Args verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. export_keras_model Exports the best Keras model to the given filename. export_autokeras_model Creates and Exports the AutoKeras model to the given filename. PortableImageSupervised init Initialize the instance. Args: graph: The graph form of the learned model predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test .","title":"image_supervised"},{"location":"temp/image_supervised/#read_images","text":"Read the images from the path and return their numpy.ndarray instance. Return a numpy.ndarray instance containing the training data.","title":"read_images"},{"location":"temp/image_supervised/#args","text":"img_file_names : List containing images names. images_dir_path : Path to the directory containing images.","title":"Args"},{"location":"temp/image_supervised/#load_image_dataset","text":"Load images from the files and labels from a csv file. Second, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path . The path to the directory containing all the images should be passed through image_path .","title":"load_image_dataset"},{"location":"temp/image_supervised/#args_1","text":"csv_file_path : CSV file path. images_path : Path where images exist.","title":"Args"},{"location":"temp/image_supervised/#returns","text":"x : Four dimensional numpy.ndarray. The channel dimension is the last dimension. y : The labels.","title":"Returns"},{"location":"temp/image_supervised/#imagesupervised","text":"The image classifier class. It is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset.","title":"ImageSupervised"},{"location":"temp/image_supervised/#attributes","text":"path : A path to the directory to save the classifier. y_encoder : An instance of OneHotEncoder for y_train (array of categorical labels). verbose : A boolean value indicating the verbosity mode. searcher_args : A dictionary containing the parameters for the searcher's init function. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default.","title":"Attributes"},{"location":"temp/image_supervised/#init","text":"Initialize the instance. The classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.","title":"init"},{"location":"temp/image_supervised/#args_2","text":"verbose : A boolean of whether the search process will be printed to stdout. path : A string. The path to a directory, where the intermediate results are saved. resume : A boolean. If True, the classifier will continue to previous work saved in path. Otherwise, the classifier will start a new search. augment : A boolean value indicating whether the data needs augmentation. If not define, then it will use the value of Constant.DATA_AUGMENTATION which is True by default.","title":"Args"},{"location":"temp/image_supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/image_supervised/#args_3","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/image_supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/image_supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/image_supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/image_supervised/#args_4","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/image_supervised/#export_keras_model","text":"Exports the best Keras model to the given filename.","title":"export_keras_model"},{"location":"temp/image_supervised/#export_autokeras_model","text":"Creates and Exports the AutoKeras model to the given filename.","title":"export_autokeras_model"},{"location":"temp/image_supervised/#portableimagesupervised","text":"","title":"PortableImageSupervised"},{"location":"temp/image_supervised/#init_1","text":"Initialize the instance. Args: graph: The graph form of the learned model","title":"init"},{"location":"temp/image_supervised/#predict_1","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/image_supervised/#args_5","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/image_supervised/#returns_2","text":"","title":"Returns"},{"location":"temp/image_supervised/#evaluate_1","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/layer_transformer/","text":"","title":"Layer transformer"},{"location":"temp/layers/","text":"","title":"Layers"},{"location":"temp/loss_function/","text":"","title":"Loss function"},{"location":"temp/metric/","text":"","title":"Metric"},{"location":"temp/model_trainer/","text":"ModelTrainer A class that is used to train the model. This class can train a Pytorch model with the given data loaders. The metric, loss_function, and model must be compatible with each other. Please see the details in the Attributes. Attributes device : A string. Indicating the device to use. 'cuda' or 'cpu'. model : An instance of Pytorch Module. The model that will be trained. train_loader : Training data wrapped in batches in Pytorch Dataloader. test_loader : Testing data wrapped in batches in Pytorch Dataloader. loss_function : A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. optimizer : The optimizer is chosen to use the Pytorch Adam optimizer. early_stop : An instance of class EarlyStop. metric : It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose : Verbosity mode. init Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose train_model Train the model. Args max_iter_num : An integer. The maximum number of epochs to train the model. The training will stop when this number is reached. max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease. The training will stop when this number is reached. GANModelTrainer init Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose","title":"model_trainer"},{"location":"temp/model_trainer/#modeltrainer","text":"A class that is used to train the model. This class can train a Pytorch model with the given data loaders. The metric, loss_function, and model must be compatible with each other. Please see the details in the Attributes.","title":"ModelTrainer"},{"location":"temp/model_trainer/#attributes","text":"device : A string. Indicating the device to use. 'cuda' or 'cpu'. model : An instance of Pytorch Module. The model that will be trained. train_loader : Training data wrapped in batches in Pytorch Dataloader. test_loader : Testing data wrapped in batches in Pytorch Dataloader. loss_function : A function with two parameters (prediction, target). There is no specific requirement for the types of the parameters, as long as they are compatible with the model and the data loaders. The prediction should be the output of the model for a batch. The target should be a batch of targets packed in the data loaders. optimizer : The optimizer is chosen to use the Pytorch Adam optimizer. early_stop : An instance of class EarlyStop. metric : It should be a subclass of class autokeras.metric.Metric. In the compute(prediction, target) function, prediction and targets are all numpy arrays converted from the output of the model and the targets packed in the data loaders. verbose : Verbosity mode.","title":"Attributes"},{"location":"temp/model_trainer/#init","text":"Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose","title":"init"},{"location":"temp/model_trainer/#train_model","text":"Train the model.","title":"train_model"},{"location":"temp/model_trainer/#args","text":"max_iter_num : An integer. The maximum number of epochs to train the model. The training will stop when this number is reached. max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease. The training will stop when this number is reached.","title":"Args"},{"location":"temp/model_trainer/#ganmodeltrainer","text":"","title":"GANModelTrainer"},{"location":"temp/model_trainer/#init_1","text":"Init the ModelTrainer with model , x_train , y_train , x_test , y_test , verbose","title":"init"},{"location":"temp/net_transformer/","text":"","title":"Net transformer"},{"location":"temp/preprocessor/","text":"OneHotEncoder A class that can format data. This class provides ways to transform data's classification label into vector. Attributes data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label. init Initialize a OneHotEncoder fit Create mapping from label to vector, and vector to label. transform Get vector for every element in the data array. inverse_transform Get label for every element in data. Cutout Randomly mask out one or more patches from an image. Args: n_holes (int): Number of patches to cut out of each image. length (int): The length (in pixels) of each square patch. call Args: img (Tensor): Tensor image of size (C, H, W). Returns: Tensor: Image with n_holes of dimension length x length cut out of it.","title":"preprocessor"},{"location":"temp/preprocessor/#onehotencoder","text":"A class that can format data. This class provides ways to transform data's classification label into vector.","title":"OneHotEncoder"},{"location":"temp/preprocessor/#attributes","text":"data : The input data n_classes : The number of classes in the classification problem. labels : The number of labels. label_to_vec : Mapping from label to vector. int_to_label : Mapping from int to label.","title":"Attributes"},{"location":"temp/preprocessor/#init","text":"Initialize a OneHotEncoder","title":"init"},{"location":"temp/preprocessor/#fit","text":"Create mapping from label to vector, and vector to label.","title":"fit"},{"location":"temp/preprocessor/#transform","text":"Get vector for every element in the data array.","title":"transform"},{"location":"temp/preprocessor/#inverse_transform","text":"Get label for every element in data.","title":"inverse_transform"},{"location":"temp/preprocessor/#cutout","text":"Randomly mask out one or more patches from an image. Args: n_holes (int): Number of patches to cut out of each image. length (int): The length (in pixels) of each square patch.","title":"Cutout"},{"location":"temp/preprocessor/#call","text":"Args: img (Tensor): Tensor image of size (C, H, W). Returns: Tensor: Image with n_holes of dimension length x length cut out of it.","title":"call"},{"location":"temp/search/","text":"Searcher Base class of all searcher classes. This class is the base class of all searcher classes, every searcher class can override its search function to implements its strategy. Attributes n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. search_tree : The data structure for storing all the searched architectures in tree structure. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. beta : A float. The beta in the UCB acquisition function. t_min : A float. The minimum temperature during simulated annealing. init Initialize the BayesianSearcher. Args n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. beta : A float. The beta in the UCB acquisition function. kernel_lambda : A float. The balance factor in the neural network kernel. t_min : A float. The minimum temperature during simulated annealing.","title":"search"},{"location":"temp/search/#searcher","text":"Base class of all searcher classes. This class is the base class of all searcher classes, every searcher class can override its search function to implements its strategy.","title":"Searcher"},{"location":"temp/search/#attributes","text":"n_classes : Number of classes in the target classification task. input_shape : Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the first layer in a model. verbose : Verbosity mode. history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'. path : A string. The path to the directory for saving the searcher. model_count : An integer. the total number of neural networks in the current searcher. descriptors : A dictionary of all the neural network architectures searched. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. search_tree : The data structure for storing all the searched architectures in tree structure. training_queue : A list of the generated architectures to be trained. x_queue : A list of trained architectures not updated to the gpr. y_queue : A list of trained architecture performances not updated to the gpr. beta : A float. The beta in the UCB acquisition function. t_min : A float. The minimum temperature during simulated annealing.","title":"Attributes"},{"location":"temp/search/#init","text":"Initialize the BayesianSearcher.","title":"init"},{"location":"temp/search/#args","text":"n_output_node : An integer, the number of classes. input_shape : A tuple. e.g. (28, 28, 1). path : A string. The path to the directory to save the searcher. verbose : A boolean. Whether to output the intermediate information to stdout. trainer_args : A dictionary. The params for the constructor of ModelTrainer. default_model_len : An integer. Number of convolutional layers in the initial architecture. default_model_width : An integer. The number of filters in each layer in the initial architecture. beta : A float. The beta in the UCB acquisition function. kernel_lambda : A float. The balance factor in the neural network kernel. t_min : A float. The minimum temperature during simulated annealing.","title":"Args"},{"location":"temp/supervised/","text":"Supervised The base class for all supervised task. Attributes verbose : A boolean value indicating the verbosity mode. init Initialize the instance. Args verbose : A boolean of whether the search process will be printed to stdout. fit Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train . Args x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. x_test : A numpy.ndarray instance containing the testing data y_test : A numpy.ndarray instance containing the label of the testing data. time_limit : The time limit for the search in seconds. final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test . PortableClass init Initialize the instance. Args graph : The graph form of the learned model predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns evaluate Return the accuracy score between predict value and y_test .","title":"supervised"},{"location":"temp/supervised/#supervised","text":"The base class for all supervised task.","title":"Supervised"},{"location":"temp/supervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/supervised/#init","text":"Initialize the instance.","title":"init"},{"location":"temp/supervised/#args","text":"verbose : A boolean of whether the search process will be printed to stdout.","title":"Args"},{"location":"temp/supervised/#fit","text":"Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/supervised/#args_1","text":"x : A numpy.ndarray instance containing the training data or the training data combined with the validation data. y : A numpy.ndarray instance containing the label of the training data. or the label of the training data combined with the validation label. x_test : A numpy.ndarray instance containing the testing data y_test : A numpy.ndarray instance containing the label of the testing data. time_limit : The time limit for the search in seconds.","title":"Args"},{"location":"temp/supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/supervised/#args_2","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_3","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/supervised/#portableclass","text":"","title":"PortableClass"},{"location":"temp/supervised/#init_1","text":"Initialize the instance.","title":"init"},{"location":"temp/supervised/#args_4","text":"graph : The graph form of the learned model","title":"Args"},{"location":"temp/supervised/#predict_1","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/supervised/#args_5","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/supervised/#returns_1","text":"","title":"Returns"},{"location":"temp/supervised/#evaluate_1","text":"Return the accuracy score between predict value and y_test .","title":"evaluate"},{"location":"temp/text_preprocessor/","text":"clean_str Tokenization/string cleaning for all string. Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py tokenlize_text Tokenlize text class. Vectorize a text corpus by transform each text in texts to a sequence of integers. Attributes max_num_words : int, max number of words in the dictionary max_seq_length : int, the length of each text sequence, padding if shorter, trim is longer x_train : list contains text data y_train : list contains label data","title":"Text preprocessor"},{"location":"temp/text_preprocessor/#clean_str","text":"Tokenization/string cleaning for all string. Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py","title":"clean_str"},{"location":"temp/text_preprocessor/#tokenlize_text","text":"Tokenlize text class. Vectorize a text corpus by transform each text in texts to a sequence of integers.","title":"tokenlize_text"},{"location":"temp/text_preprocessor/#attributes","text":"max_num_words : int, max number of words in the dictionary max_seq_length : int, the length of each text sequence, padding if shorter, trim is longer x_train : list contains text data y_train : list contains label data","title":"Attributes"},{"location":"temp/text_supervised/","text":"TextClassifier fit Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train . Args x : A numpy.ndarray instance containing the training data. y : A numpy.ndarray instance containing the label of the training data. time_limit : The time limit for the search in seconds. y_test : x_test : final_fit Final training after found the best architecture. Args x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model. predict Return predict results for the testing data. Args x_test : An instance of numpy.ndarray containing the testing data. Returns","title":"Text supervised"},{"location":"temp/text_supervised/#textclassifier","text":"","title":"TextClassifier"},{"location":"temp/text_supervised/#fit","text":"Find the best neural architecture and train it. Based on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train , y_train .","title":"fit"},{"location":"temp/text_supervised/#args","text":"x : A numpy.ndarray instance containing the training data. y : A numpy.ndarray instance containing the label of the training data. time_limit : The time limit for the search in seconds. y_test : x_test :","title":"Args"},{"location":"temp/text_supervised/#final_fit","text":"Final training after found the best architecture.","title":"final_fit"},{"location":"temp/text_supervised/#args_1","text":"x_train : A numpy.ndarray of training data. y_train : A numpy.ndarray of training targets. x_test : A numpy.ndarray of testing data. y_test : A numpy.ndarray of testing targets. trainer_args : A dictionary containing the parameters of the ModelTrainer constructor. retrain : A boolean of whether reinitialize the weights of the model.","title":"Args"},{"location":"temp/text_supervised/#predict","text":"Return predict results for the testing data.","title":"predict"},{"location":"temp/text_supervised/#args_2","text":"x_test : An instance of numpy.ndarray containing the testing data.","title":"Args"},{"location":"temp/text_supervised/#returns","text":"","title":"Returns"},{"location":"temp/unsupervised/","text":"Unsupervised The base class for all unsupervised task Attributes verbose : A boolean value indicating the verbosity mode. init Args: verbose: A boolean of whether the search process will be printed to stdout. fit Args: x_train: A numpy.ndarray instance containing the training data. generate Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"Unsupervised"},{"location":"temp/unsupervised/#unsupervised","text":"The base class for all unsupervised task","title":"Unsupervised"},{"location":"temp/unsupervised/#attributes","text":"verbose : A boolean value indicating the verbosity mode.","title":"Attributes"},{"location":"temp/unsupervised/#init","text":"Args: verbose: A boolean of whether the search process will be printed to stdout.","title":"init"},{"location":"temp/unsupervised/#fit","text":"Args: x_train: A numpy.ndarray instance containing the training data.","title":"fit"},{"location":"temp/unsupervised/#generate","text":"Args: A numpy.ndarray or torch.tensor input fed into the model to generate the output","title":"generate"},{"location":"temp/utils/","text":"ensure_dir Create directory if it does not exist ensure_file_dir Create path if it does not exist get_device If Cuda is available, use Cuda device, else use CPU device When choosing from Cuda devices, this function will choose the one with max memory available validate_xy Check x_train 's type and the shape of x_train , y_train . read_csv_file Read the csv file and returns two separate list containing files name and their labels. Args csv_file_path : Path to the CSV file. Returns file_names : List containing files names. file_label : List containing their respective labels.","title":"utils"},{"location":"temp/utils/#ensure_dir","text":"Create directory if it does not exist","title":"ensure_dir"},{"location":"temp/utils/#ensure_file_dir","text":"Create path if it does not exist","title":"ensure_file_dir"},{"location":"temp/utils/#get_device","text":"If Cuda is available, use Cuda device, else use CPU device When choosing from Cuda devices, this function will choose the one with max memory available","title":"get_device"},{"location":"temp/utils/#validate_xy","text":"Check x_train 's type and the shape of x_train , y_train .","title":"validate_xy"},{"location":"temp/utils/#read_csv_file","text":"Read the csv file and returns two separate list containing files name and their labels.","title":"read_csv_file"},{"location":"temp/utils/#args","text":"csv_file_path : Path to the CSV file.","title":"Args"},{"location":"temp/utils/#returns","text":"file_names : List containing files names. file_label : List containing their respective labels.","title":"Returns"}]}